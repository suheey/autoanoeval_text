import numpy as np
import pandas as pd
import openai
import json
import re
import os
from typing import List, Dict, Any
from .base_generator import BaseAnomalyGenerator

class HybridLLMAnomalyGenerator(BaseAnomalyGenerator):
    """í•˜ì´ë¸Œë¦¬ë“œ LLM ê¸°ë°˜ í•©ì„± ì´ìƒì¹˜ ìƒì„±ê¸° (ë¶„ì„: ìˆ˜ë™, ìƒì„±: ìë™)"""
    
    def __init__(self, api_key: str, model: str = "gpt-4", seed: int = 42, num_anomaly_conditions: int = 5):
        super().__init__(seed)
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model
        self.num_anomaly_conditions = num_anomaly_conditions
        print(f"ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ LLM ì´ìƒì¹˜ ìƒì„±ê¸° ì´ˆê¸°í™”: {model}")
        print(f"   ğŸ“Š ì´ìƒì¹˜ ì¡°ê±´ ê°œìˆ˜: {num_anomaly_conditions}ê°œ")
        print(f"   ğŸ’¡ ëª¨ë“œ: ë¶„ì„(ìˆ˜ë™) + ìƒì„±(ìë™)")
    
    def create_analysis_prompt(self, X: np.ndarray, y: np.ndarray, 
                              feature_names: List[str] = None, 
                              dataset_name: str = "Unknown",
                              num_conditions: int = None,
                              save_path: str = "./prompts") -> str:
        """1ë‹¨ê³„: íŒ¨í„´ ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ì €ì¥ (ìˆ˜ë™)"""
        
        # ì¡°ê±´ ê°œìˆ˜ ì„¤ì •
        if num_conditions is None:
            num_conditions = self.num_anomaly_conditions
        
        print(f"ğŸ“ 1ë‹¨ê³„: íŒ¨í„´ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘... (ìˆ˜ë™)")
        print(f"   ğŸ“Š ìš”ì²­ëœ ì´ìƒì¹˜ ì¡°ê±´ ê°œìˆ˜: {num_conditions}ê°œ")
        
        # ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´
        n_samples, n_features = X.shape
        n_normal = np.sum(y == 0)
        n_anomaly = np.sum(y == 1)
        
        # ì •ìƒ ë°ì´í„° í†µê³„
        X_normal = X[y == 0]
        
        # íŠ¹ì„± ì´ë¦„ ì„¤ì •
        if feature_names is None:
            feature_names = [f"Feature_{i}" for i in range(n_features)]
        
        # ì •ìƒ ìƒ˜í”Œ ì˜ˆì‹œ ìƒì„± (10ê°œ)
        normal_samples_text = []
        num_samples = min(10, len(X_normal))
        
        for i in range(num_samples):
            sample_parts = []
            for j, feature_name in enumerate(feature_names):
                value = round(X_normal[i, j], 3)
                if value == int(value):
                    value = int(value)
                sample_parts.append(f"{feature_name} is {value}")
            
            sample_text = " , ".join(sample_parts)
            normal_samples_text.append(sample_text)
        
        # ì •ìƒ ìƒ˜í”Œ ì„¹ì…˜ ìƒì„±
        normal_samples_section = ""
        for i, sample_text in enumerate(normal_samples_text, 1):
            normal_samples_section += f"Normal Sample {i}: {sample_text}\n\n"

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""**Respond with valid JSON only â€” no prose, no bullet points.**  
Your objective is to predict what combinations of values may indicate a plausible fault or anomaly scenario.

Consider the following dataset description:
â€¢ Dataset: {dataset_name}
â€¢ Total samples: {n_samples:,} (Normal: {n_normal:,}, Anomaly: {n_anomaly:,})
â€¢ Features: {n_features}

Consider the following features:
{', '.join(feature_names)}

Here are examples of normal samples from the dataset:

{normal_samples_section}Based on these {len(normal_samples_text)} normal examples, explain step-by-step what would constitute realistic anomaly patterns:

1ï¸âƒ£ Identify typical feature relationships
Normally, [describe typical relationships between features based on the examples above]

2ï¸âƒ£ Derive anomaly conditions 1
If [condition], this might be due to [reason].

3ï¸âƒ£ Derive anomaly conditions 2
Similarly, [another condition] may suggest [another reason].

Then provide mathematical conditions for anomalies:

ğŸ“Œ Anomaly Condition Examples (always combine **at least two** different features):
â€¢ [Feature_A] > [threshold_A] AND [Feature_B] < [threshold_B] â†’ ğŸ” [explanation]
â€¢ [Feature_C] > [threshold_C] AND [Feature_D] / [Feature_E] > [ratio] â†’ ğŸ” [explanation]
â€¢ [Feature_F] = [value_F] AND [Feature_G] < [threshold_G] AND [Feature_H] > [threshold_H] â†’ ğŸ” [explanation]

ğŸ“Œ Provide {num_conditions} anomaly conditions in JSON format, each with a `condition`, `explanation`, and `scenario`:

{{
    "normal_relationships": "Description of typical feature relationships observed in the normal samples",
    "anomaly_conditions": [
        {{
            "condition": "mathematical condition (e.g., LB > 200 AND AC < 1)",
            "explanation": "reason why this combination is anomalous",
            "scenario": "real-world scenario that could cause this anomaly"
        }}
    ]
}}"""
        
        # í”„ë¡¬í”„íŠ¸ ì €ì¥
        os.makedirs(save_path, exist_ok=True)
        prompt_file = os.path.join(save_path, f"{dataset_name}_analysis_prompt.txt")
        
        with open(prompt_file, 'w', encoding='utf-8') as f:
            f.write(prompt)
        
        print(f"âœ… íŒ¨í„´ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì €ì¥: {prompt_file}")
        print(f"ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print(f"   1. ìœ„ íŒŒì¼ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì›¹ LLMì— ì…ë ¥")
        print(f"   2. ê²°ê³¼ë¥¼ '{save_path}/{dataset_name}_analysis_result.json'ì— ì €ì¥")
        print(f"   3. continue_with_auto_generation() í˜¸ì¶œí•˜ì—¬ ìë™ ì§„í–‰")
        
        return prompt_file
    
    def load_analysis_result(self, dataset_name: str, json_path: str = None,
                            save_path: str = "./prompts") -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ë¡œë“œ ë° ê²€ì¦"""
        
        if json_path is None:
            json_path = os.path.join('/lab-di/nfsdata/home/suhee.yoon/autoanoeval/ADBench/autoanoeval_text/prompts', f"{dataset_name}_analysis_result.json")
        
        if not os.path.exists(json_path):
            print(f"âŒ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {json_path}")
            print(f"   ì›¹ LLM ê²°ê³¼ë¥¼ ìœ„ ê²½ë¡œì— ì €ì¥í•´ì£¼ì„¸ìš”.")
            return {"error": "JSON file not found"}
        
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                result = json.load(f)
            
            # ê²°ê³¼ ê²€ì¦
            if "anomaly_conditions" not in result:
                print(f"âŒ JSON í˜•ì‹ ì˜¤ë¥˜: 'anomaly_conditions' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {"error": "Invalid JSON format"}
            
            actual_conditions = len(result.get('anomaly_conditions', []))
            print(f"âœ… íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ (ì¡°ê±´ {actual_conditions}ê°œ)")
            
            if actual_conditions != self.num_anomaly_conditions:
                print(f"âš ï¸ ìš”ì²­í•œ ì¡°ê±´ ê°œìˆ˜({self.num_anomaly_conditions})ì™€ ìƒì„±ëœ ê°œìˆ˜({actual_conditions})ê°€ ë‹¤ë¦…ë‹ˆë‹¤.")
            
            self._print_analysis_result(result)
            return result
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {"error": f"JSON parsing error: {e}"}
        except Exception as e:
            print(f"âŒ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return {"error": f"File load error: {e}"}
    
    def generate_anomalies_from_patterns_auto(self, X: np.ndarray, y: np.ndarray,
                                             anomaly_patterns: Dict[str, Any],
                                             anomaly_count: int = None,
                                             feature_names: List[str] = None) -> np.ndarray:
        """2ë‹¨ê³„: íŒ¨í„´ ê¸°ë°˜ ìë™ ì´ìƒì¹˜ ìƒì„± (API ì‚¬ìš©)"""
        
        if anomaly_count is None:
            anomaly_count = np.sum(y == 1)
        
        print(f"ğŸ¤– 2ë‹¨ê³„: API ê¸°ë°˜ ìë™ ì´ìƒì¹˜ ìƒì„± ì¤‘... ({anomaly_count:,}ê°œ)")
        
        # ì •ìƒ ë°ì´í„° í†µê³„
        X_normal = X[y == 0]
        n_features = X_normal.shape[1]
        
        if feature_names is None:
            feature_names = [f"Feature_{i}" for i in range(n_features)]
        
        # íŠ¹ì„±ë³„ í†µê³„ ê³„ì‚°
        feature_stats = {}
        for i, name in enumerate(feature_names):
            feature_stats[name] = {
                'mean': float(np.mean(X_normal[:, i])),
                'std': float(np.std(X_normal[:, i])),
                'min': float(np.min(X_normal[:, i])),
                'max': float(np.max(X_normal[:, i]))
            }
        
        prompt = f"""**Respond with valid JSON only â€” no prose, no bullet points.**  
        Generate {anomaly_count} synthetic anomaly data points based on the following anomaly patterns:

Normal Relationships:
{anomaly_patterns.get('normal_relationships', 'Not provided')}

Anomaly Conditions:
"""
        
        for i, condition in enumerate(anomaly_patterns.get('anomaly_conditions', [])):
            prompt += f"{i+1}. {condition.get('condition', '')} â†’ {condition.get('explanation', '')}\n"
        
        prompt += f"""

Feature Statistics (Normal Data):
{json.dumps(feature_stats, indent=2)}

Generate realistic anomaly data points that satisfy the above anomaly conditions.
Ensure the generated data:
1. Follows the mathematical conditions identified
2. Maintains realistic value ranges
3. Represents diverse anomaly scenarios

Provide response in JSON format:
{{
    "anomaly_data": [
        {{{', '.join([f'"{name}": value' for name in feature_names])}}},
        {{{', '.join([f'"{name}": value' for name in feature_names])}}}
    ],
    "pattern_usage": "Which patterns were used to generate each anomaly"
}}

Generate exactly {min(anomaly_count, 100)} data points."""
        
        try:
            print(f"ğŸ”„ API í˜¸ì¶œ ì¤‘...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are an expert in synthetic anomaly generation. Create realistic anomaly data based on identified patterns."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8,
                max_tokens=1000
            )
            
            content = response.choices[0].message.content
            print(f"ğŸ” API ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸° (ì²« 500ì):")
            print(content[:500])
            print("...")
            
            # JSON ì¶”ì¶œ ì‹œë„ - ì—¬ëŸ¬ íŒ¨í„´ìœ¼ë¡œ ì‹œë„
            json_patterns = [
                r'\{.*?\}(?=\s*$)',  # ë§ˆì§€ë§‰ JSON ê°ì²´
                r'\{.*\}',           # ì²« ë²ˆì§¸ JSON ê°ì²´
                r'"anomaly_data"\s*:\s*\[.*?\]',  # anomaly_data ë°°ì—´ë§Œ
            ]
            
            result = None
            for pattern in json_patterns:
                json_match = re.search(pattern, content, re.DOTALL)
                if json_match:
                    try:
                        matched_text = json_match.group()
                        
                        # anomaly_data ë°°ì—´ë§Œ ë§¤ì¹­ëœ ê²½ìš° ì™„ì „í•œ JSONìœ¼ë¡œ ë³€í™˜
                        if matched_text.startswith('"anomaly_data"'):
                            matched_text = "{" + matched_text + "}"
                        
                        result = json.loads(matched_text)
                        print(f"âœ… JSON íŒŒì‹± ì„±ê³µ (íŒ¨í„´: {pattern[:20]}...)")
                        break
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ (íŒ¨í„´: {pattern[:20]}...): {e}")
                        continue
            
            if result is None:
                print(f"âŒ ëª¨ë“  JSON íŒŒì‹± íŒ¨í„´ ì‹¤íŒ¨")
                print(f"ğŸ” ì „ì²´ ì‘ë‹µ:")
                print(content)
                return np.array([])
            
            anomaly_data_dicts = result.get('anomaly_data', [])
                
            # ë”•ì…”ë„ˆë¦¬ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            anomaly_data = []
            for data_dict in anomaly_data_dicts:
                row = [data_dict.get(name, 0) for name in feature_names]
                anomaly_data.append(row)
            
            anomaly_data = np.array(anomaly_data)
            
            if len(anomaly_data) > 0:
                # í•„ìš”í•œ ê°œìˆ˜ë§Œí¼ ì¡°ì •
                if len(anomaly_data) > anomaly_count:
                    indices = np.random.choice(len(anomaly_data), anomaly_count, replace=False)
                    anomaly_data = anomaly_data[indices]
                elif len(anomaly_data) < anomaly_count:
                    # ë¶€ì¡±í•œ ê²½ìš° ë³µì œ
                    needed = anomaly_count - len(anomaly_data)
                    indices = np.random.choice(len(anomaly_data), needed, replace=True)
                    additional = anomaly_data[indices]
                    anomaly_data = np.vstack([anomaly_data, additional])
                
                print(f"âœ… API ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„± ì™„ë£Œ: {len(anomaly_data):,}ê°œ")
                return anomaly_data
            else:
                print(f"âŒ ìƒì„±ëœ ë°ì´í„° ì—†ìŒ")
                return np.array([])

                
        except Exception as e:
            print(f"âŒ API ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return np.array([])
    
    def generate_anomalies(self, X: np.ndarray, y: np.ndarray, 
                          anomaly_type: str = "pattern_based",
                          anomaly_count: int = None,
                          feature_names: List[str] = None,
                          dataset_name: str = "Unknown",
                          num_conditions: int = None,
                          save_path: str = "./prompts",
                          hybrid_step: str = "start") -> np.ndarray:
        """í•˜ì´ë¸Œë¦¬ë“œ ì´ìƒì¹˜ ìƒì„± í•¨ìˆ˜"""
        
        print(f"ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ LLM ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„± ì‹œì‘")
        
        if anomaly_count is None:
            anomaly_count = np.sum(y == 1)
        
        if hybrid_step == "start":
            # 1ë‹¨ê³„: ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± (ìˆ˜ë™)
            analysis_prompt_file = self.create_analysis_prompt(
                X, y, feature_names, dataset_name, num_conditions, save_path
            )
            
            print(f"\nâ¸ï¸ ìˆ˜ë™ ê°œì… í•„ìš”:")
            print(f"   1. {analysis_prompt_file} ë‚´ìš©ì„ ì›¹ LLMì— ì…ë ¥")
            print(f"   2. ê²°ê³¼ë¥¼ {save_path}/{dataset_name}_analysis_result.jsonì— ì €ì¥")
            print(f"   3. hybrid_step='continue'ë¡œ ë‹¤ì‹œ ì‹¤í–‰")
            
            return np.array([])  # ìˆ˜ë™ ê°œì… ëŒ€ê¸°
            
        elif hybrid_step == "continue":
            # 1ë‹¨ê³„ ê²°ê³¼ ë¡œë“œ
            anomaly_patterns = self.load_analysis_result(dataset_name, save_path=save_path)
            
            if "error" in anomaly_patterns:
                print(f"âŒ ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨")
                return np.array([])
            
            # 2ë‹¨ê³„: ìë™ ì´ìƒì¹˜ ìƒì„± (API)
            anomalies = self.generate_anomalies_from_patterns_auto(
                X, y, anomaly_patterns, anomaly_count, feature_names
            )
            
            return anomalies
            
        else:
            print(f"âŒ ì˜ëª»ëœ hybrid_step ê°’: {hybrid_step}")
            return np.array([])
    
    def continue_with_auto_generation(self, X: np.ndarray, y: np.ndarray,
                                     feature_names: List[str] = None,
                                     dataset_name: str = "Unknown",
                                     anomaly_count: int = None,
                                     save_path: str = "./prompts") -> np.ndarray:
        """ë¶„ì„ ì™„ë£Œ í›„ ìë™ ìƒì„± ì§„í–‰"""
        
        print(f"ğŸš€ ë¶„ì„ ì™„ë£Œ í›„ ìë™ ìƒì„± ì‹œì‘...")
        
        return self.generate_anomalies(
            X, y, anomaly_count=anomaly_count, feature_names=feature_names,
            dataset_name=dataset_name, save_path=save_path, hybrid_step="continue"
        )
    
    def _print_analysis_result(self, result: Dict[str, Any]):
        """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        print("\nğŸ“‹ ì´ìƒì¹˜ íŒ¨í„´ ë¶„ì„ ê²°ê³¼:")
        
        if "normal_relationships" in result:
            print(f"\n1ï¸âƒ£ ì¼ë°˜ì ì¸ ê´€ê³„:")
            print(f"   {result['normal_relationships']}")
        
        if "anomaly_conditions" in result:
            print(f"\nğŸ“Œ ì´ìƒì¹˜ ì¡°ê±´:")
            for i, condition in enumerate(result['anomaly_conditions']):
                print(f"   {i+1}. {condition.get('condition', '')} â†’ ğŸ” {condition.get('explanation', '')}")
                if condition.get('scenario'):
                    print(f"      ì‹œë‚˜ë¦¬ì˜¤: {condition['scenario']}")
        