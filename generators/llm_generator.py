import numpy as np
import pandas as pd
import openai
import json
import re
from typing import List, Dict, Any
from .base_generator import BaseAnomalyGenerator

class LLMAnomalyGenerator(BaseAnomalyGenerator):
    """LLM ê¸°ë°˜ í•©ì„± ì´ìƒì¹˜ ìƒì„±ê¸°"""
    
    def __init__(self, api_key: str, model: str = "gpt-4", seed: int = 42, num_anomaly_conditions: int = 5):
        super().__init__(seed)
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model
        self.num_anomaly_conditions = num_anomaly_conditions
        print(f"ğŸ¤– LLM ì´ìƒì¹˜ ìƒì„±ê¸° ì´ˆê¸°í™”: {model}")
        print(f"   ğŸ“Š ì´ìƒì¹˜ ì¡°ê±´ ê°œìˆ˜: {num_anomaly_conditions}ê°œ")
    
    def analyze_anomaly_patterns(self, X: np.ndarray, y: np.ndarray, 
                                feature_names: List[str] = None, 
                                dataset_name: str = "Unknown",
                                num_conditions: int = None) -> Dict[str, Any]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ íŒ¨í„´ ë¶„ì„"""
        
        # ì¡°ê±´ ê°œìˆ˜ ì„¤ì • (íŒŒë¼ë¯¸í„° > ì¸ìŠ¤í„´ìŠ¤ ì„¤ì • > ê¸°ë³¸ê°’)
        if num_conditions is None:
            num_conditions = self.num_anomaly_conditions
        
        print(f"ğŸ¤– LLM ì´ìƒì¹˜ íŒ¨í„´ ë¶„ì„ ì‹œì‘: {dataset_name}")
        print(f"   ğŸ“Š ìš”ì²­ëœ ì´ìƒì¹˜ ì¡°ê±´ ê°œìˆ˜: {num_conditions}ê°œ")
        
        # ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´
        n_samples, n_features = X.shape
        n_normal = np.sum(y == 0)
        n_anomaly = np.sum(y == 1)
        
        # ì •ìƒ ë°ì´í„° í†µê³„
        X_normal = X[y == 0]
        
        # íŠ¹ì„± ì´ë¦„ ì„¤ì •
        if feature_names is None:
            feature_names = [f"Feature_{i}" for i in range(n_features)]
        
        # ì •ìƒ ìƒ˜í”Œ ì˜ˆì‹œ ìƒì„± (10ê°œ) - í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜
        normal_samples_text = []
        num_samples = min(10, len(X_normal))  # ìµœëŒ€ 10ê°œê¹Œì§€
        
        for i in range(num_samples):
            sample_parts = []
            for j, feature_name in enumerate(feature_names):
                value = round(X_normal[i, j], 3)
                # ì •ìˆ˜ê°’ì¸ ê²½ìš° .0 ì œê±°
                if value == int(value):
                    value = int(value)
                sample_parts.append(f"{feature_name} is {value}")
            
            # ë” ì½ê¸° ì‰½ê²Œ í¬ë§·íŒ…
            sample_text = " , ".join(sample_parts)
            normal_samples_text.append(sample_text)
        
        print(f"ì •ìƒ ìƒ˜í”Œ {num_samples}ê°œ ìƒì„±ë¨")
        print("ì²« ë²ˆì§¸ ì˜ˆì‹œ:", normal_samples_text[0] if normal_samples_text else "ì—†ìŒ")
        
        # í”„ë¡¬í”„íŠ¸ì— ë„£ì„ ì •ìƒ ìƒ˜í”Œ ì˜ˆì‹œë“¤ ìƒì„±
        normal_samples_section = ""
        for i, sample_text in enumerate(normal_samples_text, 1):
            normal_samples_section += f"Normal Sample {i}: {sample_text}\n\n"

        prompt = f"""**Respond with valid JSON only â€” no prose, no bullet points.**  
        Your objective is to predict what combinations of values may indicate a plausible fault or anomaly scenario.

Consider the following dataset description:
â€¢ Dataset: {dataset_name}
â€¢ Total samples: {n_samples:,} (Normal: {n_normal:,}, Anomaly: {n_anomaly:,})
â€¢ Features: {n_features}

Consider the following features:
{', '.join(feature_names)}

Here are examples of normal samples from the dataset:

{normal_samples_section}Based on these {len(normal_samples_text)} normal examples, explain step-by-step what would constitute realistic anomaly patterns:

1ï¸âƒ£ Identify typical feature relationships
Normally, [describe typical relationships between features based on the examples above]

2ï¸âƒ£ Derive anomaly conditions 1
If [condition], this might be due to [reason].

3ï¸âƒ£ Derive anomaly conditions 2
Similarly, [another condition] may suggest [another reason].

Then provide mathematical conditions for anomalies:

ğŸ“Œ Anomaly Condition Examples (always combine **at least two** different features):
â€¢ [Feature_A] > [threshold_A] AND [Feature_B] < [threshold_B] â†’ ğŸ” [explanation]
â€¢ [Feature_C] > [threshold_C] AND [Feature_D] / [Feature_E] > [ratio] â†’ ğŸ” [explanation]
â€¢ [Feature_F] = [value_F] AND [Feature_G] < [threshold_G] AND [Feature_H] > [threshold_H] â†’ ğŸ” [explanation]

ğŸ“Œ Provide {num_conditions} anomaly conditions in JSON format, each with a `condition`, `explanation`, and `scenario`:

{{
    "normal_relationships": "Description of typical feature relationships observed in the normal samples",
    "anomaly_conditions": [
        {{
            "condition": "mathematical condition (e.g., LB > 200 AND AC < 1)",
            "explanation": "reason why this combination is anomalous",
            "scenario": "real-world scenario that could cause this anomaly"
        }}
    ]
}}"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are an expert in anomaly detection and domain analysis. Provide step-by-step reasoning for anomaly patterns. Output ONLY a JSON object** matching the schema exactly."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            content = response.choices[0].message.content
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            
            if json_match:
                result = json.loads(json_match.group())
                
                # ì´ìƒì¹˜ ì¡°ê±´ ê°œìˆ˜ ê²€ì¦
                actual_conditions = len(result.get('anomaly_conditions', []))
                print(f"âœ… LLM íŒ¨í„´ ë¶„ì„ ì™„ë£Œ (ì¡°ê±´ {actual_conditions}ê°œ/{num_conditions}ê°œ ìš”ì²­)")
                
                if actual_conditions != num_conditions:
                    print(f"âš ï¸ ìš”ì²­í•œ ì¡°ê±´ ê°œìˆ˜({num_conditions})ì™€ ìƒì„±ëœ ê°œìˆ˜({actual_conditions})ê°€ ë‹¤ë¦…ë‹ˆë‹¤.")
                
                self._print_analysis_result(result)
                return result
            else:
                print(f"âŒ JSON í˜•ì‹ ì‘ë‹µ ì—†ìŒ")
                return {"error": "No JSON response"}
                
        except Exception as e:
            print(f"âŒ LLM íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def generate_anomalies_from_patterns(self, X: np.ndarray, y: np.ndarray,
                                       anomaly_patterns: Dict[str, Any],
                                       anomaly_count: int = None,
                                       feature_names: List[str] = None) -> np.ndarray:
        """íŒ¨í„´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ìƒì¹˜ ìƒì„±"""
        
        if anomaly_count is None:
            anomaly_count = np.sum(y == 1)
        
        print(f"ğŸ¯ íŒ¨í„´ ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„±: {anomaly_count:,}ê°œ")
        
        # ì •ìƒ ë°ì´í„° í†µê³„
        X_normal = X[y == 0]
        n_features = X_normal.shape[1]
        
        if feature_names is None:
            feature_names = [f"Feature_{i}" for i in range(n_features)]
        
        # íŠ¹ì„±ë³„ í†µê³„ ê³„ì‚°
        feature_stats = {}
        for i, name in enumerate(feature_names):
            feature_stats[name] = {
                'mean': float(np.mean(X_normal[:, i])),
                'std': float(np.std(X_normal[:, i])),
                'min': float(np.min(X_normal[:, i])),
                'max': float(np.max(X_normal[:, i]))
            }
        
        prompt = f"""Generate {anomaly_count} synthetic anomaly data points based on the following anomaly patterns:

Normal Relationships:
{anomaly_patterns.get('normal_relationships', 'Not provided')}

Anomaly Conditions:
"""
        
        for i, condition in enumerate(anomaly_patterns.get('anomaly_conditions', [])):
            prompt += f"{i+1}. {condition.get('condition', '')} â†’ {condition.get('explanation', '')}\n"
        
        prompt += f"""

Feature Statistics (Normal Data):
{json.dumps(feature_stats, indent=2)}

Generate realistic anomaly data points that satisfy the above anomaly conditions.
Ensure the generated data:
1. Follows the mathematical conditions identified
2. Maintains realistic value ranges
3. Represents diverse anomaly scenarios

Provide response in JSON format:
{{
    "anomaly_data": [
        {{{', '.join([f'"{name}": value' for name in feature_names])}}},
        {{{', '.join([f'"{name}": value' for name in feature_names])}}}
    ],
    "pattern_usage": "Which patterns were used to generate each anomaly"
}}

Generate exactly {min(anomaly_count, 100)} data points."""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are an expert in synthetic anomaly generation. Create realistic anomaly data based on identified patterns."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8,
                max_tokens=2000
            )
            
            content = response.choices[0].message.content
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            
            if json_match:
                result = json.loads(json_match.group())
                anomaly_data_dicts = result.get('anomaly_data', [])
                
                # ë”•ì…”ë„ˆë¦¬ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
                anomaly_data = []
                for data_dict in anomaly_data_dicts:
                    row = [data_dict.get(name, 0) for name in feature_names]
                    anomaly_data.append(row)
                
                anomaly_data = np.array(anomaly_data)
                
                if len(anomaly_data) > 0:
                    # í•„ìš”í•œ ê°œìˆ˜ë§Œí¼ ì¡°ì •
                    if len(anomaly_data) > anomaly_count:
                        indices = np.random.choice(len(anomaly_data), anomaly_count, replace=False)
                        anomaly_data = anomaly_data[indices]
                    elif len(anomaly_data) < anomaly_count:
                        # ë¶€ì¡±í•œ ê²½ìš° ë³µì œ
                        needed = anomaly_count - len(anomaly_data)
                        indices = np.random.choice(len(anomaly_data), needed, replace=True)
                        additional = anomaly_data[indices]
                        anomaly_data = np.vstack([anomaly_data, additional])
                    
                    print(f"âœ… íŒ¨í„´ ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„± ì™„ë£Œ: {len(anomaly_data):,}ê°œ")
                    return anomaly_data
                else:
                    print(f"âŒ ìƒì„±ëœ ë°ì´í„° ì—†ìŒ")
                    return np.array([])
            else:
                print(f"âŒ JSON í˜•ì‹ ì‘ë‹µ ì—†ìŒ")
                return np.array([])
                
        except Exception as e:
            print(f"âŒ íŒ¨í„´ ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return np.array([])
    
    def generate_anomalies(self, X: np.ndarray, y: np.ndarray, 
                          anomaly_type: str = "pattern_based",
                          anomaly_count: int = None,
                          feature_names: List[str] = None,
                          dataset_name: str = "Unknown",
                          num_conditions: int = None) -> np.ndarray:
        """í†µí•© ì´ìƒì¹˜ ìƒì„± í•¨ìˆ˜"""
        
        print(f"ğŸš€ LLM ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„± ì‹œì‘")
        
        # 1ë‹¨ê³„: ì´ìƒì¹˜ íŒ¨í„´ ë¶„ì„
        anomaly_patterns = self.analyze_anomaly_patterns(
            X, y, feature_names, dataset_name, num_conditions
        )
        
        if "error" in anomaly_patterns:
            print(f"âŒ íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨")
            return np.array([])
        
        # 2ë‹¨ê³„: íŒ¨í„´ ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„±
        anomalies = self.generate_anomalies_from_patterns(
            X, y, anomaly_patterns, anomaly_count, feature_names
        )
        
        return anomalies
    
    def set_anomaly_conditions_count(self, count: int):
        """ì´ìƒì¹˜ ì¡°ê±´ ê°œìˆ˜ ì„¤ì •"""
        self.num_anomaly_conditions = count
        print(f"ğŸ“Š ì´ìƒì¹˜ ì¡°ê±´ ê°œìˆ˜ê°€ {count}ê°œë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def get_anomaly_conditions_count(self) -> int:
        """í˜„ì¬ ì„¤ì •ëœ ì´ìƒì¹˜ ì¡°ê±´ ê°œìˆ˜ ë°˜í™˜"""
        return self.num_anomaly_conditions
    
    def _print_analysis_result(self, result: Dict[str, Any]):
        """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        print("\nğŸ“‹ ì´ìƒì¹˜ íŒ¨í„´ ë¶„ì„ ê²°ê³¼:")
        
        if "normal_relationships" in result:
            print(f"\n1ï¸âƒ£ ì¼ë°˜ì ì¸ ê´€ê³„:")
            print(f"   {result['normal_relationships']}")
        
        if "anomaly_conditions" in result:
            print(f"\nğŸ“Œ ì´ìƒì¹˜ ì¡°ê±´:")
            for i, condition in enumerate(result['anomaly_conditions']):
                print(f"   {i+1}. {condition.get('condition', '')} â†’ ğŸ” {condition.get('explanation', '')}")
                if condition.get('scenario'):
                    print(f"      ì‹œë‚˜ë¦¬ì˜¤: {condition['scenario']}")
        
        print()  # ë¹ˆ ì¤„ ì¶”ê°€