import numpy as np
import pandas as pd
import os
import time
import argparse
import sys
from datetime import datetime

# ìƒˆë¡œìš´ ëª¨ë“ˆ imports
from config.settings import RANDOM_SEED, ANOMALY_TYPES, OPENAI_API_KEY, GEMINI_API_KEY
from data.loader import load_dataset
from data.preprocessor import prepare_dataset_splits
from generators.validation_set_generator import generate_validation_sets
from models.selection import run_model_selection_experiment
from utils.io import setup_logging

def main(args):
    """ë©”ì¸ ì‹¤í—˜ ì‹¤í–‰ í•¨ìˆ˜ (í•˜ì´ë¸Œë¦¬ë“œ LLM ì§€ì›)"""
    print("ğŸ”¬ LLM ê¸°ë°˜ ì´ìƒì¹˜ íŒ¨í„´ ë¶„ì„ ì‹¤í—˜ ì‹œì‘")
    print("=" * 80)
    
    # LLM ëª¨ë“œ í™•ì¸
    if args.hybrid_llm_mode:
        print("ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ LLM ëª¨ë“œ: ë¶„ì„(ìˆ˜ë™) + ìƒì„±(ìë™)")
        if args.llm_step:
            print(f"ğŸ“‹ í˜„ì¬ ë‹¨ê³„: {args.llm_step}")
    
    # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    if args.hybrid_llm_mode:
        llm_suffix = "_hybrid_llm"
    else:
        llm_suffix = "_llm" if OPENAI_API_KEY else ""
    
    results_dir = f"./results/{args.dataset_name}_experiment_results_{timestamp}{llm_suffix}"
    os.makedirs(results_dir, exist_ok=True)

    # ë¡œê·¸ íŒŒì¼ ì„¤ì •
    log_file = setup_logging(results_dir)
    
    try:
        # 1. ë°ì´í„°ì…‹ ì¤€ë¹„
        print(f"\nğŸ“Š ë°ì´í„°ì…‹ ë¡œë“œ: {args.dataset_name}")
        
        # ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”© ë°©ì‹ ì„ íƒ
        cat_encoding = getattr(args, 'cat_encoding', 'int')
        
        X_original, y_original, metadata = load_dataset(
            dataset_name=args.dataset_name,
            cat_encoding=cat_encoding
        )
        
        # 2. ë°ì´í„°ì…‹ ë¶„í• 
        experiment_start_time = time.time()
        
        X_normal_train, X_normal_val, X_val_real, y_val_real, X_test, y_test, X_anomaly_val = prepare_dataset_splits(
            X_original, y_original, metadata
        )
        
        # íŠ¹ì„± ì´ë¦„ ìƒì„±
        feature_names = metadata.get('column_names', [f"Feature_{i}" for i in range(X_original.shape[1])])
        
        # 3. í†µí•© ê²€ì¦ ì„¸íŠ¸ ìƒì„± (í•˜ì´ë¸Œë¦¬ë“œ LLM ì§€ì›)
        synthetic_val_sets = generate_validation_sets(
            X_original=X_original, 
            y_original=y_original, 
            X_normal_val=X_normal_val, 
            X_anomaly_val=X_anomaly_val,
            feature_names=feature_names,
            dataset_name=args.dataset_name,
            llm_generate=args.llm_generate,
            openai_api_key=OPENAI_API_KEY,
            use_statistical_fallback=args.use_statistical_fallback,
            num_anomaly_conditions=args.num_anomaly_conditions,
            results_dir=results_dir,
            hybrid_llm_mode=args.hybrid_llm_mode,    # í•˜ì´ë¸Œë¦¬ë“œ LLM ëª¨ë“œ (ìƒˆë¡œ ì¶”ê°€)
            llm_step=args.llm_step                   # LLM ë‹¨ê³„
        )
        
        # í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œì—ì„œ ìˆ˜ë™ ê°œì…ì´ í•„ìš”í•œ ê²½ìš°
        if args.hybrid_llm_mode and len(synthetic_val_sets) == 0:
            print(f"\nâ¸ï¸ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ - ìˆ˜ë™ ê°œì… ì™„ë£Œ í›„ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ìë™ ì§„í–‰:")
            if args.llm_step == "start" or args.llm_step is None:
                print(f"   python main.py --dataset_name {args.dataset_name} --llm_generate --hybrid_llm_mode --llm_step continue --use_statistical_fallback")
            return
        
        # ìˆ˜ë™ ëª¨ë“œì—ì„œ ìˆ˜ë™ ê°œì…ì´ í•„ìš”í•œ ê²½ìš°
        if len(synthetic_val_sets) == 0:
            print(f"\nâ¸ï¸ ìˆ˜ë™ ê°œì… ì™„ë£Œ í›„ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ê³„ì† ì§„í–‰:")
            if args.llm_step == "start" or args.llm_step is None:
                print(f"   python main.py --dataset_name {args.dataset_name} --llm_generate --llm_step continue_analysis")
            elif args.llm_step == "continue_analysis":
                print(f"   python main.py --dataset_name {args.dataset_name} --llm_generate --llm_step continue_generation")
            elif args.llm_step == "continue_generation":
                print(f"   python main.py --dataset_name {args.dataset_name} --llm_generate --llm_step auto")
            return
        
        # ìƒì„±ëœ ê²€ì¦ ì„¸íŠ¸ í™•ì¸
        print(f"\nğŸ“‹ ìƒì„±ëœ ê²€ì¦ ì„¸íŠ¸: {list(synthetic_val_sets.keys())}")
        
        if not synthetic_val_sets:
            print("âŒ ê²€ì¦ ì„¸íŠ¸ê°€ í•˜ë‚˜ë„ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # LLM íŒ¨í„´ í¬í•¨ ì—¬ë¶€ í™•ì¸
        has_llm = 'llm_patterns' in synthetic_val_sets
        has_statistical = any(key in ANOMALY_TYPES for key in synthetic_val_sets.keys())
        
        print(f"ğŸ¤– LLM íŒ¨í„´: {'í¬í•¨' if has_llm else 'ì—†ìŒ'}")
        print(f"ğŸ“Š í†µê³„ì  ë°©ë²•: {'í¬í•¨' if has_statistical else 'ì—†ìŒ'}")
        print(f"ğŸ” t-SNE ì‹œê°í™”: ìƒì„± ì™„ë£Œ")
        
        # 4. ëª¨ë¸ ì„ íƒ ì‹¤í—˜ ì‹¤í–‰
        try:
            print(f"\nğŸš€ ëª¨ë¸ ì„ íƒ ì‹¤í—˜ ì‹¤í–‰...")
            model_start_time = time.time()
            
            all_results, best_models, evaluation_metrics = run_model_selection_experiment(
                X_normal_train=X_normal_train,
                X_val_real=X_val_real,
                y_val_real=y_val_real,
                synthetic_val_sets=synthetic_val_sets,
                X_test=X_test,
                y_test=y_test,
                results_dir=results_dir
            )
            
            model_time = time.time() - model_start_time
            total_time = time.time() - experiment_start_time
            
            # ì„±ëŠ¥ ìš”ì•½
            print(f"\nâ±ï¸ ì‹¤í—˜ ì‹œê°„ ìš”ì•½:")
            print(f"   ë°ì´í„° ì¤€ë¹„: {model_start_time - experiment_start_time:.2f}s")
            print(f"   ëª¨ë¸ í•™ìŠµ/í‰ê°€: {model_time:.2f}s")
            print(f"   ì „ì²´ ì‹¤í—˜ ì‹œê°„: {total_time:.2f}s")
            
            # LLM vs í†µê³„ì  ë°©ë²• ì„±ëŠ¥ ë¹„êµ
            if has_llm and has_statistical:
                print(f"\nğŸ¯ LLM vs í†µê³„ì  ë°©ë²• ì„±ëŠ¥ ë¹„êµ:")
                
                if 'llm_patterns' in best_models:
                    llm_auc = best_models['llm_patterns']['test_auc']
                    if args.hybrid_llm_mode:
                        mode_text = "í•˜ì´ë¸Œë¦¬ë“œ LLM"
                    else:
                        mode_text = "API LLM"
                    print(f"   ğŸ¤– {mode_text} íŒ¨í„´ Best Model: {best_models['llm_patterns']['model_name']} (Test AUC: {llm_auc:.4f})")
                
                stat_aucs = []
                for key in best_models.keys():
                    if key in ANOMALY_TYPES:
                        stat_aucs.append(best_models[key]['test_auc'])
                        print(f"   ğŸ“Š {key}: {best_models[key]['model_name']} (Test AUC: {best_models[key]['test_auc']:.4f})")
                
                if stat_aucs and 'llm_patterns' in best_models:
                    avg_stat_auc = np.mean(stat_aucs)
                    print(f"   ğŸ“ˆ í†µê³„ì  ë°©ë²• í‰ê·  AUC: {avg_stat_auc:.4f}")
                    print(f"   ğŸ” LLM vs í†µê³„ì  ë°©ë²• ì°¨ì´: {llm_auc - avg_stat_auc:+.4f}")
            
        except ImportError:
            print(f"âš ï¸ model_selection_enhanced ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤. íŒ¨í„´ ë¶„ì„ê¹Œì§€ë§Œ ìˆ˜í–‰ë©ë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì„ íƒ ì‹¤í—˜ ì‹¤íŒ¨: {e}")
        
        print(f"\nğŸ‰ ì‹¤í—˜ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: {results_dir}")
        
        # ìµœì¢… ìš”ì•½
        if has_llm:
            if args.hybrid_llm_mode:
                mode_text = "í•˜ì´ë¸Œë¦¬ë“œ LLM (ë¶„ì„: ìˆ˜ë™, ìƒì„±: ìë™)"
            else:
                mode_text = "API LLM"
            print(f"ğŸ¤– {mode_text} íŒ¨í„´ ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„±ì´ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤!")
        if has_statistical:
            print(f"ğŸ“Š í†µê³„ì  ë°©ë²• ê¸°ë°˜ ì´ìƒì¹˜ë„ í•¨ê»˜ ë¹„êµë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ” t-SNE ì‹œê°í™”ë¥¼ í†µí•´ ìƒì„±ëœ anomalyë“¤ì˜ ë¶„í¬ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        
        if args.hybrid_llm_mode:
            print(f"ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œë¡œ ë¶„ì„ì€ ë¬´ë£Œ(ì›¹), ìƒì„±ì€ ìë™(API)ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"\nâŒ ì‹¤í—˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
    finally:
        log_file.close()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="LLM ê¸°ë°˜ ì´ìƒì¹˜ íŒ¨í„´ ë¶„ì„ ì‹¤í—˜ (í•˜ì´ë¸Œë¦¬ë“œ LLM ì§€ì›)")
    parser.add_argument("--dataset_name", type=str, required=True, 
                       help="ë°ì´í„°ì…‹ ì´ë¦„")
    parser.add_argument("--llm_generate", action="store_true", default=False,
                       help="LLM ê¸°ë°˜ generation")
    parser.add_argument("--use_statistical_fallback", action="store_true", default=False,
                       help="LLMê³¼ í•¨ê»˜ í†µê³„ì  ë°©ë²•ë„ ì‚¬ìš©")
    parser.add_argument("--num_anomaly_conditions", type=int, default=5,
                       help="LLMì´ ìƒì„±í•  ì´ìƒì¹˜ ì¡°ê±´ ê°œìˆ˜")
    parser.add_argument("--cat_encoding", type=str, default="int", 
                       choices=["int", "onehot", "int_emb"],
                       help="ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”© ë°©ì‹")
    parser.add_argument("--scaling_type", type=str, default="standard",
                       choices=["standard", "minmax", "none"],
                       help="ìŠ¤ì¼€ì¼ë§ ë°©ì‹")
    parser.add_argument("--hybrid_llm_mode", action="store_true", default=False,
                       help="í•˜ì´ë¸Œë¦¬ë“œ LLM ëª¨ë“œ: ë¶„ì„(ìˆ˜ë™) + ìƒì„±(ìë™) (ë¶€ë¶„ ë¹„ìš© ì ˆì•½)")
    parser.add_argument("--llm_step", type=str, 
                       choices=["start", "continue", "continue_analysis", "continue_generation", "auto"],
                       help="LLM ë‹¨ê³„ ì œì–´")
    
    args = parser.parse_args()
    
    # LLM ëª¨ë“œ ê²€ì¦
    if args.hybrid_llm_mode and not args.llm_generate:
        print("âŒ ìˆ˜ë™/í•˜ì´ë¸Œë¦¬ë“œ LLM ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ --llm_generateë„ í•¨ê»˜ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        sys.exit(1)
    
    main(args)