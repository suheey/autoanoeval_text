import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder
import os
from datetime import datetime
import urllib.request
from sklearn.model_selection import train_test_split
from data_generator import SimpleDataGenerator
from model_selection_enhanced import run_model_selection_experiment
import argparse
import sys
import time

# GPU ê°€ì† í™•ì¸
try:
    import cupy as cp
    GPU_AVAILABLE = cp.cuda.is_available()
    if GPU_AVAILABLE:
        print(f"ğŸš€ GPU ê°€ì† ì‚¬ìš© ê°€ëŠ¥!")
        print(f"ğŸ“Š GPU: {cp.cuda.Device().mem_info}")
        print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {cp.cuda.Device().mem_info[1] / 1e9:.1f} GB")
except ImportError:
    GPU_AVAILABLE = False
    print("âš ï¸ CuPyê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    print("GPU ê°€ì†ì„ ì›í•˜ì‹œë©´: pip install cupy-cuda12x")

# ì„¤ì •
RANDOM_SEED = 42
ANOMALY_TYPES = ['local', 'cluster', 'global', 'discrepancy']

class Tee(object):
    """í„°ë¯¸ë„ê³¼ íŒŒì¼ ë™ì‹œ ì¶œë ¥ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    def __init__(self, *files):
        self.files = files
    def write(self, obj):
        for f in self.files:
            f.write(obj)
            f.flush()
    def flush(self):
        for f in self.files:
            f.flush()

def load_dataset(dataset_name):
    """CSV ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    csv_path = f'/lab-di/nfsdata/home/suhee.yoon/autoanoeval/data/adbench_column/{dataset_name}.csv'    
    print(f"ğŸ“¥ CSV ë°ì´í„°ì…‹ ë¡œë“œ: {csv_path}")
    
    if not os.path.exists(csv_path):
        print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_path}")
        raise FileNotFoundError(f"Dataset file not found: {csv_path}")
    
    df = pd.read_csv(csv_path)
    print(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„° í˜•íƒœ: {df.shape}")

    y = df['label'].values
    df = df.drop(columns=['label'])  # label ì œê±°

    # âœ… ìˆ«ì / ë¬¸ìì—´ feature ìë™ êµ¬ë¶„
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    string_cols = df.select_dtypes(include=['object', 'string']).columns
    
    print(f"ğŸ“ˆ ìˆ«ì ì»¬ëŸ¼: {len(numeric_cols)}ê°œ, ë¬¸ìì—´ ì»¬ëŸ¼: {len(string_cols)}ê°œ")

    # âœ… ìˆ«ì feature normalize
    scaler = MinMaxScaler()
    X_numeric = scaler.fit_transform(df[numeric_cols].values)

    # âœ… ë¬¸ìì—´ feature â†’ integer encoding
    X_strings = []
    for col in string_cols:
        unique_vals = np.unique(df[col])
        val_to_int = {val: idx for idx, val in enumerate(unique_vals)}
        encoded_col = np.vectorize(val_to_int.get)(df[col].values).reshape(-1, 1)
        X_strings.append(encoded_col)
        print(f"   ğŸ”¤ {col}: {len(unique_vals)}ê°œ ê³ ìœ ê°’ â†’ ì •ìˆ˜ ì¸ì½”ë”©")

    # âœ… ìˆ«ì + ë¬¸ìì—´ feature ê²°í•©
    if X_strings:
        X_strings = np.hstack(X_strings)
        X = np.hstack([X_numeric, X_strings])
        print(f"ğŸ“Š ìµœì¢… feature ì°¨ì›: {X_numeric.shape[1]} (ìˆ«ì) + {X_strings.shape[1]} (ë¬¸ìì—´) = {X.shape[1]}")
    else:
        X = X_numeric
        print(f"ğŸ“Š ìµœì¢… feature ì°¨ì›: {X.shape[1]} (ìˆ«ìë§Œ)")

    print(f"ğŸ·ï¸ ë ˆì´ë¸” ë¶„í¬: ì •ìƒ {np.sum(y == 0):,}ê°œ, ì´ìƒ {np.sum(y == 1):,}ê°œ")
    
    return X, y

def download_dataset(url, filename):
    """ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (CSV ì‚¬ìš© ì‹œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)"""
    print(f"â„¹ï¸ CSV íŒŒì¼ ì§ì ‘ ë¡œë“œ ëª¨ë“œ. ë‹¤ìš´ë¡œë“œ ìƒëµ.")
    pass

def prepare_dataset_splits(X_original, y_original):
    """GPU ê°€ì† ë°ì´í„°ì…‹ ë¶„í• """
    print(f"ğŸ“Š ì›ë³¸ ë°ì´í„°: {X_original.shape}")
    print(f"ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬ - ì •ìƒ: {np.sum(y_original == 0):,}, ì´ìƒ: {np.sum(y_original == 1):,}")

    # ëŒ€ìš©ëŸ‰ ë°ì´í„° ìµœì í™”
    max_normal = 3000
    max_anomaly = 500
    
    if np.sum(y_original == 0) > max_normal * 2:  # ì¶©ë¶„í•œ ì—¬ìœ ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì œí•œ
        print(f"âš¡ ëŒ€ìš©ëŸ‰ ì •ìƒ ë°ì´í„° ê°ì§€. {max_normal:,}ê°œë¡œ ì œí•œ")
    if np.sum(y_original == 1) > max_anomaly * 2:
        print(f"âš¡ ëŒ€ìš©ëŸ‰ ì´ìƒ ë°ì´í„° ê°ì§€. {max_anomaly:,}ê°œë¡œ ì œí•œ")

    # ë°ì´í„° ì œí•œ ë° ë¶„ë¦¬
    X_normal = X_original[y_original == 0][:max_normal]
    X_anomaly = X_original[y_original == 1][:max_anomaly]
    
    # GPU ê°€ì† ë°ì´í„° ë¶„í•  (ê°€ëŠ¥í•œ ê²½ìš°)
    if GPU_AVAILABLE and len(X_normal) > 10000:
        print("ğŸš€ GPU ê°€ì† ë°ì´í„° ë¶„í•  ì ìš©")
        X_normal, X_normal_holdout = gpu_train_test_split(X_normal, test_size=0.4)
        X_anomaly_val, X_anomaly_test = gpu_train_test_split(X_anomaly, test_size=0.7)
        X_normal_val, X_normal_test = gpu_train_test_split(X_normal_holdout, test_size=0.5)
    else:
        # ê¸°ì¡´ CPU ë°©ì‹
        X_normal_train, X_normal_holdout = train_test_split(
            X_normal, test_size=0.4, random_state=RANDOM_SEED
        )
        X_anomaly_val, X_anomaly_test = train_test_split(
            X_anomaly, test_size=0.7, random_state=RANDOM_SEED
        )
        X_normal_val, X_normal_test = train_test_split(
            X_normal_holdout, test_size=0.5, random_state=RANDOM_SEED
        )
    
    # ìµœì¢… ë°ì´í„°ì…‹ êµ¬ì„±
    X_val_real = np.vstack([X_normal_val, X_anomaly_val])
    y_val_real = np.concatenate([np.zeros(len(X_normal_val)), np.ones(len(X_anomaly_val))])
    
    X_test = np.vstack([X_normal_test, X_anomaly_test])
    y_test = np.concatenate([np.zeros(len(X_normal_test)), np.ones(len(X_anomaly_test))])
    
    # GPU ê°€ì† ë°ì´í„° ì…”í”Œ
    X_val_real, y_val_real = gpu_shuffle_data(X_val_real, y_val_real)
    X_test, y_test = gpu_shuffle_data(X_test, y_test)
    
    print(f"\nğŸ“‹ ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ:")
    print(f"   Train (ì •ìƒë§Œ): {X_normal_train.shape}")
    print(f"   Real Validation: {X_val_real.shape} (ì •ìƒ: {np.sum(y_val_real == 0):,}, ì´ìƒ: {np.sum(y_val_real == 1):,})")
    print(f"   Test: {X_test.shape} (ì •ìƒ: {np.sum(y_test == 0):,}, ì´ìƒ: {np.sum(y_test == 1):,})")
    
    return X_normal_train, X_normal_val, X_val_real, y_val_real, X_test, y_test, X_anomaly_val

def gpu_train_test_split(X, test_size=0.3):
    """GPU ê°€ì† train-test split"""
    if GPU_AVAILABLE:
        X_gpu = cp.asarray(X)
        n_samples = len(X_gpu)
        n_test = int(n_samples * test_size)
        
        # GPUì—ì„œ ëœë¤ ì¸ë±ìŠ¤ ìƒì„±
        indices = cp.random.permutation(n_samples)
        test_indices = indices[:n_test]
        train_indices = indices[n_test:]
        
        # GPUì—ì„œ ë¶„í• 
        X_train_gpu = X_gpu[train_indices]
        X_test_gpu = X_gpu[test_indices]
        
        # CPUë¡œ ì´ë™
        return cp.asnumpy(X_train_gpu), cp.asnumpy(X_test_gpu)
    else:
        # CPU í´ë°±
        return train_test_split(X, test_size=test_size, random_state=RANDOM_SEED)

def gpu_shuffle_data(X, y):
    """GPU ê°€ì† ë°ì´í„° ì…”í”Œ"""
    if GPU_AVAILABLE and len(X) > 1000:
        # GPUì—ì„œ ì…”í”Œ
        idx_gpu = cp.random.RandomState(RANDOM_SEED).permutation(len(y))
        idx = cp.asnumpy(idx_gpu)
    else:
        # CPU ì…”í”Œ
        idx = np.random.RandomState(RANDOM_SEED).permutation(len(y))
    
    return X[idx], y[idx]

def generate_synthetic_validation_sets(X_original, y_original, X_normal_val, X_anomaly_val, use_gpu=True):
    """GPU ê°€ì† í•©ì„± ì´ìƒì¹˜ ê²€ì¦ ì„¸íŠ¸ ìƒì„±"""
    print(f"\nğŸ§ª Synthetic Anomaly ê²€ì¦ ì„¸íŠ¸ ìƒì„±... ({'GPU' if use_gpu and GPU_AVAILABLE else 'CPU'})")
    
    # GPU ì‚¬ìš© ì—¬ë¶€ ê²°ì •
    actual_use_gpu = use_gpu and GPU_AVAILABLE
    
    if actual_use_gpu:
        print(f"ğŸš€ GPU ê°€ì† ëª¨ë“œ í™œì„±í™”")
        # PyTorch CUDA ë©”ëª¨ë¦¬ ì •ë³´ëŠ” ì œí•œì ì´ë¯€ë¡œ ê°„ë‹¨íˆ í‘œì‹œ
        props = torch.cuda.get_device_properties(0)
        print(f"ğŸ’¾ GPU ì´ ë©”ëª¨ë¦¬: {props.total_memory / 1e9:.1f} GB")
        
        # ë°ì´í„° í¬ê¸° ê¸°ë°˜ ê°„ë‹¨í•œ ê²€ì‚¬
        data_size_gb = X_original.nbytes / 1e9
        if data_size_gb > 2.0:  # 2GB ì´ìƒ ì‹œ ì£¼ì˜
            print(f"âš ï¸ ë°ì´í„° í¬ê¸°({data_size_gb:.1f}GB)ê°€ í¼. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì£¼ì˜")
    
    # ë°ì´í„° ìƒì„±ê¸° ì´ˆê¸°í™” (PyTorch ë²„ì „ì€ SimpleDataGeneratorì— ë§ì¶° ìˆ˜ì • í•„ìš”)
    data_generator = SimpleDataGenerator(seed=RANDOM_SEED, use_gpu=actual_use_gpu)
    synthetic_val_sets = {}
    synthetic_anomalies_by_type = {}
    
    # ê° ìœ í˜•ë³„ ì‹œê°„ ì¸¡ì •
    generation_times = {}
    
    # ê° ìœ í˜•ë³„ í•©ì„± ì´ìƒì¹˜ ìƒì„±
    for anomaly_type in ANOMALY_TYPES:
        print(f"   ğŸ”¬ {anomaly_type} ìœ í˜• ìƒì„± ì¤‘...")
        
        # ì‹œê°„ ì¸¡ì • ì‹œì‘
        start_time = time.time()
        
        try:
            synthetic_anomalies = data_generator.generate_anomalies(
                X=X_original,
                y=y_original,
                anomaly_type=anomaly_type,
                alpha=5,
                percentage=0.2,
                anomaly_count=len(X_anomaly_val)
            )
            
            generation_time = time.time() - start_time
            generation_times[anomaly_type] = generation_time
            
            synthetic_anomalies_by_type[anomaly_type] = synthetic_anomalies
            
            # ê²€ì¦ ì„¸íŠ¸ êµ¬ì„±
            X_val_synthetic = np.vstack([X_normal_val, synthetic_anomalies])
            y_val_synthetic = np.concatenate([np.zeros(len(X_normal_val)), np.ones(len(synthetic_anomalies))])
            
            # GPU ê°€ì† ì…”í”Œ
            X_val_synthetic, y_val_synthetic = gpu_shuffle_data(X_val_synthetic, y_val_synthetic)
            
            synthetic_val_sets[anomaly_type] = (X_val_synthetic, y_val_synthetic)
            
            print(f"      âœ… {anomaly_type}: {X_val_synthetic.shape} "
                  f"(ì •ìƒ: {np.sum(y_val_synthetic == 0):,}, ì´ìƒ: {np.sum(y_val_synthetic == 1):,}) "
                  f"[{generation_time:.2f}s]")
            
        except Exception as e:
            print(f"      âŒ {anomaly_type} ìƒì„± ì‹¤íŒ¨: {e}")
            generation_times[anomaly_type] = None
    
    # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
    print(f"\nâš¡ ìƒì„± ì‹œê°„ ìš”ì•½ ({'GPU' if actual_use_gpu else 'CPU'}):")
    total_time = 0
    for anomaly_type, gen_time in generation_times.items():
        if gen_time is not None:
            print(f"   {anomaly_type:12s}: {gen_time:6.2f}s")
            total_time += gen_time
        else:
            print(f"   {anomaly_type:12s}: Failed")
    
    if total_time > 0:
        print(f"   {'Total':12s}: {total_time:6.2f}s")
        print(f"   {'Average':12s}: {total_time/len([t for t in generation_times.values() if t is not None]):6.2f}s")
    
    return synthetic_val_sets

def check_gpu_requirements(X_original, y_original):
    """GPU ì‚¬ìš© ê°€ëŠ¥ì„± ë° ê¶Œì¥ì‚¬í•­ ê²€ì‚¬"""
    print(f"\nğŸ” GPU ê°€ì† ìš”êµ¬ì‚¬í•­ ë¶„ì„:")
    
    # ë°ì´í„° í¬ê¸° ë¶„ì„
    data_size_mb = X_original.nbytes / 1e6
    n_samples, n_features = X_original.shape
    n_normal = np.sum(y_original == 0)
    n_anomaly = np.sum(y_original == 1)
    
    print(f"   ğŸ“Š ë°ì´í„° í¬ê¸°: {data_size_mb:.1f} MB ({n_samples:,} x {n_features})")
    print(f"   ğŸ“Š ì •ìƒ/ì´ìƒ: {n_normal:,} / {n_anomaly:,}")
    
    # GPU ì‚¬ìš© ê¶Œì¥ì‚¬í•­
    if not GPU_AVAILABLE:
        print(f"   âŒ GPU ì‚¬ìš© ë¶ˆê°€ (CuPy ë¯¸ì„¤ì¹˜)")
        return False
    
    # GPU ë©”ëª¨ë¦¬ í™•ì¸
    free_mem_gb = cp.cuda.Device().mem_info[0] / 1e9
    total_mem_gb = cp.cuda.Device().mem_info[1] / 1e9
    data_size_gb = data_size_mb / 1000
    
    print(f"   ğŸ’¾ GPU ë©”ëª¨ë¦¬: {free_mem_gb:.1f}/{total_mem_gb:.1f} GB ì‚¬ìš©ê°€ëŠ¥")
    
    # ì„±ëŠ¥ ì˜ˆì¸¡
    if n_samples < 5000:
        speedup_estimate = "1-2x"
        recommendation = "CPU ê¶Œì¥ (ì‘ì€ ë°ì´í„°)"
        use_gpu = False
    elif n_samples < 20000:
        speedup_estimate = "2-5x"
        recommendation = "GPU ê¶Œì¥"
        use_gpu = True
    else:
        speedup_estimate = "5-20x"
        recommendation = "GPU ê°•ë ¥ ê¶Œì¥"
        use_gpu = True
    
    # ë©”ëª¨ë¦¬ ì¶©ë¶„ì„± ê²€ì‚¬
    if data_size_gb > free_mem_gb * 0.7:
        print(f"   âš ï¸ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ìœ„í—˜. CPU ì‚¬ìš© ê¶Œì¥")
        use_gpu = False
    
    print(f"   ğŸš€ ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: {speedup_estimate}")
    print(f"   ğŸ’¡ ê¶Œì¥ì‚¬í•­: {recommendation}")
    
    return use_gpu

def main(args):
    """ë©”ì¸ ì‹¤í—˜ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”¬ Synthetic Anomaly ê¸°ë°˜ ëª¨ë¸ ì„ íƒ ì‹¤ìš©ì„± ê²€ì¦ ì‹¤í—˜ ì‹œì‘")
    print("=" * 80)
    
    # GPU ìƒíƒœ í™•ì¸
    if GPU_AVAILABLE:
        print(f"ğŸš€ GPU ê°€ì† í™œì„±í™”: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        print("ğŸŒ CPU ëª¨ë“œë¡œ ì‹¤í–‰")
    
    # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    gpu_suffix = "_gpu" if GPU_AVAILABLE else "_cpu"
    results_dir = f"./result_metric/{args.dataset_name}_experiment_results_{timestamp}{gpu_suffix}"
    os.makedirs(results_dir, exist_ok=True)

    # ë¡œê·¸ íŒŒì¼ ì„¤ì •
    log_file = open(os.path.join(results_dir, "experiment_log.txt"), "w")
    sys.stdout = Tee(sys.stdout, log_file)
    sys.stderr = Tee(sys.stderr, log_file)
    
    try:
        # 1. ë°ì´í„°ì…‹ ì¤€ë¹„ (CSV ë¡œë“œ)
        print(f"\nğŸ“Š ë°ì´í„°ì…‹ ë¡œë“œ: {args.dataset_name}")
        X_original, y_original = load_dataset(args.dataset_name)
        
        # 2. GPU ì‚¬ìš© ê°€ëŠ¥ì„± ê²€ì‚¬
        use_gpu_recommended = check_gpu_requirements(X_original, y_original)
        
        # ì‚¬ìš©ì GPU ì„¤ì • ë°˜ì˜
        use_gpu = args.use_gpu and use_gpu_recommended if hasattr(args, 'use_gpu') else use_gpu_recommended
        
        # 3. ë°ì´í„°ì…‹ ë¶„í• 
        # 3. ë°ì´í„°ì…‹ ë¶„í• 
        experiment_start_time = time.time()
        
        X_normal_train, X_normal_val, X_val_real, y_val_real, X_test, y_test, X_anomaly_val = prepare_dataset_splits(
            X_original, y_original
        )
        
        # 4. í•©ì„± ì´ìƒì¹˜ ê²€ì¦ ì„¸íŠ¸ ìƒì„± (GPU ê°€ì†)
        synthetic_val_sets = generate_synthetic_validation_sets(
            X_original, y_original, X_normal_val, X_anomaly_val, use_gpu=use_gpu
        )
        
        # 5. ëª¨ë¸ ì„ íƒ ì‹¤í—˜ ì‹¤í–‰
        print(f"\nğŸš€ ëª¨ë¸ ì„ íƒ ì‹¤í—˜ ì‹¤í–‰...")
        model_start_time = time.time()
        
        all_results, best_models, evaluation_metrics = run_model_selection_experiment(
            X_normal_train=X_normal_train,
            X_val_real=X_val_real,
            y_val_real=y_val_real,
            synthetic_val_sets=synthetic_val_sets,
            X_test=X_test,
            y_test=y_test,
            results_dir=results_dir
        )
        
        model_time = time.time() - model_start_time
        total_time = time.time() - experiment_start_time
        
        # 6. ì„±ëŠ¥ ìš”ì•½
        print(f"\nâ±ï¸ ì‹¤í—˜ ì‹œê°„ ìš”ì•½:")
        print(f"   í•©ì„± ë°ì´í„° ìƒì„±: {model_start_time - experiment_start_time:.2f}s")
        print(f"   ëª¨ë¸ í•™ìŠµ/í‰ê°€: {model_time:.2f}s")
        print(f"   ì „ì²´ ì‹¤í—˜ ì‹œê°„: {total_time:.2f}s")
        
        # GPU ì‚¬ìš© í†µê³„ ì €ì¥ (PyTorch ê¸°ë°˜)
        if GPU_AVAILABLE:
            gpu_stats = {
                'gpu_used': use_gpu,
                'gpu_name': torch.cuda.get_device_name(0),
                'gpu_memory_total': torch.cuda.get_device_properties(0).total_memory / 1e9,
                'data_size_mb': X_original.nbytes / 1e6,
                'total_time': total_time
            }
            
            # GPU í†µê³„ë¥¼ íŒŒì¼ë¡œ ì €ì¥
            import json
            with open(os.path.join(results_dir, 'gpu_performance.json'), 'w') as f:
                json.dump(gpu_stats, f, indent=2)
        
        print(f"\nğŸ‰ ì‹¤í—˜ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: {results_dir}")
        
        if GPU_AVAILABLE and use_gpu:
            print(f"ğŸš€ GPU ê°€ì†ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"\nâŒ ì‹¤í—˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (PyTorch)
        if GPU_AVAILABLE:
            try:
                torch.cuda.empty_cache()
                print("ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
            except:
                pass
        
        raise
    finally:
        log_file.close()
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (PyTorch)
        if GPU_AVAILABLE:
            try:
                torch.cuda.empty_cache()
            except:
                pass

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Synthetic Anomaly ê¸°ë°˜ ëª¨ë¸ ì„ íƒ ì‹¤ìš©ì„± ê²€ì¦ ì‹¤í—˜")
    parser.add_argument("--dataset_name", type=str, required=True, 
                       help="ADBench ë°ì´í„°ì…‹ ì´ë¦„ (ì˜ˆ: cardio, satellite)")
    parser.add_argument("--use_gpu", action="store_true", default=True,
                       help="GPU ê°€ì† ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)")
    parser.add_argument("--no_gpu", action="store_true", default=False,
                       help="GPU ì‚¬ìš© ê°•ì œ ë¹„í™œì„±í™”")
    
    args = parser.parse_args()
    
    # GPU ì‚¬ìš© ì„¤ì • ì²˜ë¦¬
    if args.no_gpu:
        args.use_gpu = False
    
    # ì‹œì‘ ì „ GPU ìƒíƒœ ì¶œë ¥
    if GPU_AVAILABLE and args.use_gpu:
        print("ğŸš€ GPU ê°€ì† ëª¨ë“œë¡œ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ")
    else:
        print("ğŸŒ CPU ëª¨ë“œë¡œ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ")
    
    main(args)