import numpy as np
import os
from datetime import datetime
import urllib.request
from sklearn.model_selection import train_test_split
from data_generator import SimpleDataGenerator
from gmm_cot_generator import GMM_CoT_AnomalyGenerator  # ìƒˆë¡œìš´ GMM CoT ëª¨ë“ˆ ì„í¬íŠ¸
from visualization_cot import visualize_tsne
from model_selection import run_model_selection_experiment
import argparse
import sys

# ì„¤ì •
RANDOM_SEED = 42
ANOMALY_TYPES = ['local', 'cluster', 'global', 'discrepancy']  # ê¸°ì¡´ 4ê°€ì§€ ì´ìƒì¹˜ ìœ í˜•

# Cardiotocography ë° ì˜ë£Œ ë°ì´í„° ê´€ë ¨ íŠ¹ì„± ì´ë¦„ ì •ì˜
MEDICAL_FEATURE_NAMES = {
    # Cardiotocography ë°ì´í„°ì…‹ (íƒœì•„ ì‹¬ë°•ë™ ëª¨ë‹ˆí„°ë§)
    'cardiotocography': ['LB', 'AC', 'FM', 'UC', 'ASTV', 'MSTV', 'ALTV', 'MLTV', 
                        'DL', 'DS', 'DP', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 
                        'Mode', 'Mean', 'Median', 'Variance', 'Tendency'],
    'cardio': ['LB', 'AC', 'FM', 'UC', 'ASTV', 'MSTV', 'ALTV', 'MLTV', 
               'DL', 'DS', 'DP', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 
               'Mode', 'Mean', 'Median', 'Variance'],
    'ctg': ['LB', 'AC', 'FM', 'UC', 'ASTV', 'MSTV', 'ALTV', 'MLTV', 
            'DL', 'DS', 'DP', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 
            'Mode', 'Mean', 'Median', 'Variance']
}

class Tee(object):
    def __init__(self, *files):
        self.files = files
    def write(self, obj):
        for f in self.files:
            f.write(obj)
            f.flush()  # ë²„í¼ ë°”ë¡œ ë¹„ìš°ê¸°
    def flush(self):
        for f in self.files:
            f.flush()

# ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
def download_dataset(url, filename):
    if not os.path.exists(filename):
        print(f"{filename} ë‹¤ìš´ë¡œë“œ ì¤‘...")
        urllib.request.urlretrieve(url, filename)
        print(f"{filename} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
    else:
        print(f"{filename}ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")

def is_medical_dataset(dataset_name):
    """ì˜ë£Œ ê´€ë ¨ ë°ì´í„°ì…‹ì¸ì§€ í™•ì¸"""
    medical_keywords = ['cardio', 'ctg', 'thyroid', 'heart', 'ecg', 'medical', 'health']
    return any(keyword in dataset_name.lower() for keyword in medical_keywords)

def get_feature_names_for_dataset(dataset_name, actual_feature_count):
    """ë°ì´í„°ì…‹ì— ë§ëŠ” íŠ¹ì„± ì´ë¦„ ë°˜í™˜"""
    dataset_lower = dataset_name.lower()
    
    # ì˜ë£Œ ë°ì´í„°ì…‹ì¸ ê²½ìš° íŠ¹í™”ëœ íŠ¹ì„± ì´ë¦„ ì‚¬ìš©
    for key, feature_names in MEDICAL_FEATURE_NAMES.items():
        if key in dataset_lower:
            # ì‹¤ì œ íŠ¹ì„± ê°œìˆ˜ì— ë§ì¶° ì¡°ì •
            if len(feature_names) >= actual_feature_count:
                return feature_names[:actual_feature_count]
            else:
                # ë¶€ì¡±í•˜ë©´ generic ì´ë¦„ìœ¼ë¡œ í™•ì¥
                extended_names = feature_names + [f'feature_{i}' for i in range(len(feature_names), actual_feature_count)]
                return extended_names
    
    # ì¼ë°˜ ë°ì´í„°ì…‹ì¸ ê²½ìš° generic íŠ¹ì„± ì´ë¦„ ì‚¬ìš©
    return [f'feature_{i}' for i in range(actual_feature_count)]

def generate_gmm_cot_validation_sets(X_normal_val, X_anomaly_val, dataset_name, results_dir):
    """
    GMM CoT ê¸°ë°˜ í•©ì„± ê²€ì¦ ì„¸íŠ¸ ìƒì„±
    
    Parameters:
    - X_normal_val: ì •ìƒ ê²€ì¦ ë°ì´í„°
    - X_anomaly_val: ì´ìƒ ê²€ì¦ ë°ì´í„° (ê°œìˆ˜ ì°¸ì¡°ìš©)
    - dataset_name: ë°ì´í„°ì…‹ ì´ë¦„
    - results_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
    
    Returns:
    - cot_validation_sets: CoT ê¸°ë°˜ ê²€ì¦ ì„¸íŠ¸ ë”•ì…”ë„ˆë¦¬
    """
    print(f"\n{'='*60}")
    print(f"ğŸ§  GMM CoT ê¸°ë°˜ í•©ì„± ì´ìƒì¹˜ ìƒì„± ì‹œì‘")
    print(f"{'='*60}")
    
    # GMM CoT ìƒì„±ê¸° ì´ˆê¸°í™”
    cot_generator = GMM_CoT_AnomalyGenerator(seed=RANDOM_SEED)
    
    # íŠ¹ì„± ì´ë¦„ ì„¤ì •
    actual_feature_count = X_normal_val.shape[1]
    feature_names = get_feature_names_for_dataset(dataset_name, actual_feature_count)
    cot_generator.set_feature_names(feature_names)
    
    is_medical = is_medical_dataset(dataset_name)
    print(f"ë°ì´í„°ì…‹: {dataset_name}")
    print(f"ì˜ë£Œ ë°ì´í„°ì…‹ ì—¬ë¶€: {is_medical}")
    print(f"íŠ¹ì„± ìˆ˜: {actual_feature_count}")
    print(f"ì‚¬ìš©í•  íŠ¹ì„± ì´ë¦„: {feature_names[:5]}..." if len(feature_names) > 5 else f"ì‚¬ìš©í•  íŠ¹ì„± ì´ë¦„: {feature_names}")
    
    # GMM í•™ìŠµ
    try:
        print(f"\nğŸ”§ GMM í•™ìŠµ ì¤‘...")
        cot_generator.fit_gmm_normal(X_normal_val, max_components=8)  # ì»´í¬ë„ŒíŠ¸ ìˆ˜ ì œí•œ
    except Exception as e:
        print(f"âŒ GMM í•™ìŠµ ì‹¤íŒ¨: {e}")
        print("GMM CoT ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {}
    
    # CoT ê·œì¹™ ìƒì„±
    cot_rules = cot_generator.generate_cot_rules()
    
    # ê° CoT ê·œì¹™ë³„ë¡œ í•©ì„± ê²€ì¦ ì„¸íŠ¸ ìƒì„±
    cot_validation_sets = {}
    target_anomaly_count = len(X_anomaly_val)
    
    if is_medical:
        # ì˜ë£Œ ë°ì´í„°ì…‹ì¸ ê²½ìš° ë” ë§ì€ ì˜í•™ì  ê·œì¹™ ì‚¬ìš©
        selected_rules = list(cot_rules.keys())[:4]  # ì²˜ìŒ 4ê°œ ê·œì¹™ ì‚¬ìš©
        alpha = 3.5  # ì˜í•™ ë°ì´í„°ì— ì í•©í•œ í™•ì¥ ê³„ìˆ˜ (ë³´ìˆ˜ì )
        max_attempts = 3  # ì‹œê°„ ì ˆì•½
    else:
        # ì¼ë°˜ ë°ì´í„°ì…‹ì¸ ê²½ìš° ì¼ë¶€ ê·œì¹™ë§Œ ì‚¬ìš© (ì ì‘ì ìœ¼ë¡œ)
        selected_rules = ['abnormal_histogram_pattern', 'bradycardia_with_low_variability']  # ì¼ë°˜ì ìœ¼ë¡œ ì ìš© ê°€ëŠ¥í•œ ê·œì¹™
        alpha = 5.0  # ì¼ë°˜ì ì¸ í™•ì¥ ê³„ìˆ˜
        max_attempts = 2  # ë” ì ì€ ì‹œë„
    
    print(f"\nğŸ“‹ ì‚¬ìš©í•  CoT ê·œì¹™ ({len(selected_rules)}ê°œ): {selected_rules}")
    print(f"ëª©í‘œ ì´ìƒì¹˜ ê°œìˆ˜: {target_anomaly_count}")
    print(f"GMM í™•ì¥ ê³„ìˆ˜ (alpha): {alpha}")
    
    successful_rules = 0
    
    for i, rule_name in enumerate(selected_rules, 1):
        try:
            print(f"\n--- [{i}/{len(selected_rules)}] {rule_name} ê·œì¹™ ì²˜ë¦¬ ì¤‘ ---")
            
            # CoT í•„í„°ë§ ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„±
            synthetic_anomalies = cot_generator.generate_cot_filtered_anomalies(
                target_count=target_anomaly_count,
                rule_name=rule_name,
                alpha=alpha,
                max_attempts=max_attempts
            )
            
            if len(synthetic_anomalies) > 0:
                # ì •ìƒ ë°ì´í„°ì™€ ê²°í•©í•˜ì—¬ ê²€ì¦ ì„¸íŠ¸ êµ¬ì„±
                actual_normal_count = min(len(X_normal_val), len(synthetic_anomalies))
                X_val_cot = np.vstack([X_normal_val[:actual_normal_count], synthetic_anomalies])
                y_val_cot = np.concatenate([np.zeros(actual_normal_count), 
                                           np.ones(len(synthetic_anomalies))])
                
                # ë°ì´í„° ì…”í”Œ
                idx = np.random.RandomState(RANDOM_SEED).permutation(len(y_val_cot))
                X_val_cot = X_val_cot[idx]
                y_val_cot = y_val_cot[idx]
                
                # ì§§ì€ ì´ë¦„ìœ¼ë¡œ ì €ì¥ (ì‹œê°í™” ì‹œ ê°€ë…ì„±ì„ ìœ„í•´)
                short_rule_name = rule_name.replace('_with_', '_').replace('_low_', '_')[:20]
                cot_validation_sets[f'cot_{short_rule_name}'] = (X_val_cot, y_val_cot)
                
                successful_rules += 1
                print(f"âœ… {rule_name} ê²€ì¦ ì„¸íŠ¸ ìƒì„± ì™„ë£Œ")
                print(f"   ê²€ì¦ ì„¸íŠ¸ í¬ê¸°: {X_val_cot.shape}")
                print(f"   ì •ìƒ: {np.sum(y_val_cot == 0)}, ì´ìƒ: {np.sum(y_val_cot == 1)}")
            else:
                print(f"âŒ {rule_name} ê·œì¹™ìœ¼ë¡œ ì´ìƒì¹˜ ìƒì„± ì‹¤íŒ¨ (í•„í„°ë§ ê²°ê³¼ ì—†ìŒ)")
                
        except Exception as e:
            print(f"âŒ {rule_name} ê·œì¹™ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue
    
    # ìƒì„± ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ¯ GMM CoT ê²€ì¦ ì„¸íŠ¸ ìƒì„± ì™„ë£Œ")
    print(f"ì„±ê³µí•œ ê·œì¹™: {successful_rules}/{len(selected_rules)}")
    print(f"ìƒì„±ëœ CoT ê²€ì¦ ì„¸íŠ¸: {len(cot_validation_sets)}ê°œ")
    
    # ìƒì„±ëœ ì´ìƒì¹˜ ë¶„ì„ ë° ì‹œê°í™” (ì˜ë£Œ ë°ì´í„°ì…‹ì´ê³  ì„±ê³µí•œ ê·œì¹™ì´ ìˆëŠ” ê²½ìš°)
    if is_medical and cot_validation_sets:
        try:
            print(f"\nğŸ“Š CoT ì´ìƒì¹˜ í†µê³„ ë¶„ì„ ì¤‘...")
            
            # ë¶„ì„ìš© ì´ìƒì¹˜ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            rule_anomalies = {}
            for cot_key, (X_val, y_val) in cot_validation_sets.items():
                rule_name = cot_key.replace('cot_', '')
                anomalies = X_val[y_val == 1]
                rule_anomalies[rule_name] = anomalies
            
            # í†µê³„ ë¶„ì„
            cot_generator.analyze_generated_anomalies(rule_anomalies)
            
            # ì‹œê°í™” ì €ì¥ (ì˜ë£Œ ë°ì´í„°ì¸ ê²½ìš°ë§Œ)
            if len(rule_anomalies) > 0:
                print(f"\nğŸ“ˆ CoT ì´ìƒì¹˜ ë¶„í¬ ì‹œê°í™” ì¤‘...")
                
                import matplotlib
                matplotlib.use('Agg')  # GUI ì—†ëŠ” í™˜ê²½ì„ ìœ„í•´
                import matplotlib.pyplot as plt
                plt.ioff()  # ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ ë„ê¸°
                
                # ì£¼ìš” ì˜ë£Œ íŠ¹ì„±ë§Œ ì‹œê°í™”
                medical_features = ['LB', 'AC', 'ASTV', 'DL'] if is_medical else feature_names[:4]
                available_features = [f for f in medical_features if f in feature_names]
                
                if available_features:
                    fig = cot_generator.visualize_anomaly_distribution(
                        X_normal_val, 
                        rule_anomalies, 
                        features_to_plot=available_features[:4]  # ìµœëŒ€ 4ê°œ íŠ¹ì„±
                    )
                    
                    if fig is not None:
                        # ê·¸ë˜í”„ ì €ì¥
                        viz_filename = os.path.join(results_dir, 'cot_anomalies_distribution.png')
                        fig.savefig(viz_filename, dpi=300, bbox_inches='tight')
                        plt.close(fig)
                        print(f"âœ… CoT ì´ìƒì¹˜ ë¶„í¬ ì‹œê°í™”ê°€ {viz_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"âš ï¸ CoT ì´ìƒì¹˜ ë¶„ì„/ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {e}")
    
    return cot_validation_sets

def main(args):
    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = f"{args.dataset_name}_experiment_results_{timestamp}"
    if not os.path.exists(results_dir):
        os.makedirs(results_dir)

    # âœ… log.txtë¡œ + í„°ë¯¸ë„ ë™ì‹œì— ì¶œë ¥
    log_file = open(os.path.join(results_dir, "log.txt"), "w")
    sys.stdout = Tee(sys.stdout, log_file)
    sys.stderr = Tee(sys.stderr, log_file)
    
    print(f"ğŸš€ ì‹¤í—˜ ì‹œì‘: {args.dataset_name}")
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬: {results_dir}")
    
    # ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
    dataset_path = f'/lab-di/nfsdata/home/suhee.yoon/autoanoeval/ADBench/adbench/datasets/Classical/{args.dataset_name}.npz'
    dataset_url = f"https://github.com/Minqi824/ADBench/raw/main/adbench/datasets/Classical/{args.dataset_name}.npz"
    download_dataset(dataset_url, dataset_path)

    # ë°ì´í„°ì…‹ ë¡œë“œ
    print("ğŸ“¥ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    data = np.load(dataset_path, allow_pickle=True)
    X_original, y_original = data['X'], data['y']

    print(f"ì›ë³¸ ë°ì´í„°ì…‹ shape: {X_original.shape}")
    print(f"ì›ë³¸ í´ë˜ìŠ¤ ë¶„í¬ - ì •ìƒ: {np.sum(y_original == 0)}, ì´ìƒ: {np.sum(y_original == 1)}")

    # ë°ì´í„°ì…‹ ì¤€ë¹„: ì •ìƒ ë°ì´í„°ì™€ ì´ìƒ ë°ì´í„° ë¶„ë¦¬
    X_normal = X_original[y_original == 0][:5000]
    X_anomaly = X_original[y_original == 1][:1000]
    
    # 1. ì •ìƒ ë°ì´í„° ë¶„í• : í•™ìŠµìš©(train)ê³¼ ê²€ì¦/í…ŒìŠ¤íŠ¸ìš©(holdout)
    X_normal_train, X_normal_holdout = train_test_split(X_normal, test_size=0.4, random_state=RANDOM_SEED)
    
    # 2. ì‹¤ì œ ì´ìƒ ë°ì´í„° ë¶„í• : ê²€ì¦ìš©(30%)ê³¼ í…ŒìŠ¤íŠ¸ìš©(70%)
    X_anomaly_val, X_anomaly_test = train_test_split(X_anomaly, test_size=0.7, random_state=RANDOM_SEED)
    
    # 3. ê²€ì¦ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ì •ìƒ ë°ì´í„° ì¶”ê°€ (holdout ë°ì´í„°ì˜ ì ˆë°˜ì”©)
    X_normal_val, X_normal_test = train_test_split(X_normal_holdout, test_size=0.5, random_state=RANDOM_SEED)
    
    # Real anomaly validation setê³¼ test set ìƒì„±
    X_val_real = np.vstack([X_normal_val, X_anomaly_val])
    y_val_real = np.concatenate([np.zeros(len(X_normal_val)), np.ones(len(X_anomaly_val))])
    
    X_test = np.vstack([X_normal_test, X_anomaly_test])
    y_test = np.concatenate([np.zeros(len(X_normal_test)), np.ones(len(X_anomaly_test))])
    
    # ê° ë°ì´í„°ì…‹ ì…”í”Œ
    def shuffle_data(X, y):
        idx = np.random.RandomState(RANDOM_SEED).permutation(len(y))
        return X[idx], y[idx]
    
    X_val_real, y_val_real = shuffle_data(X_val_real, y_val_real)
    X_test, y_test = shuffle_data(X_test, y_test)
    
    print(f"\nğŸ“Š ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ:")
    print(f"Train set (ì •ìƒë§Œ): {X_normal_train.shape}")
    print(f"Real validation set: {X_val_real.shape}, ì •ìƒ: {np.sum(y_val_real == 0)}, ì´ìƒ: {np.sum(y_val_real == 1)}")
    print(f"Test set: {X_test.shape}, ì •ìƒ: {np.sum(y_test == 0)}, ì´ìƒ: {np.sum(y_test == 1)}")
    
    # ===== ê¸°ì¡´ ë°©ì‹: ì—¬ëŸ¬ ìœ í˜•ì˜ Synthetic Anomaly ìƒì„± =====
    print(f"\n{'='*60}")
    print(f"ğŸ”§ ê¸°ì¡´ ë°©ì‹ í•©ì„± ì´ìƒì¹˜ ìƒì„±")
    print(f"{'='*60}")
    
    data_generator = SimpleDataGenerator(seed=RANDOM_SEED)
    synthetic_val_sets = {}
    synthetic_anomalies_by_type = {}  # ê° ìœ í˜•ë³„ ì´ìƒì¹˜ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ì¶”ê°€
    
    for anomaly_type in ANOMALY_TYPES:
        print(f"\n{anomaly_type} ìœ í˜•ì˜ í•©ì„± ì´ìƒì¹˜ë¡œ ê²€ì¦ ì„¸íŠ¸ ìƒì„± ì¤‘...")
        
        # í•©ì„± ì´ìƒì¹˜ ìƒì„± (ì‹¤ì œ ì´ìƒì¹˜ì™€ ë™ì¼í•œ ê°œìˆ˜ë¡œ)
        synthetic_anomalies = data_generator.generate_anomalies(
            X=X_original,
            y=y_original,
            anomaly_type=anomaly_type,
            alpha=5,  # local, cluster ì´ìƒì¹˜ ê°•ë„
            percentage=0.2,  # global ì´ìƒì¹˜ ë²”ìœ„
            anomaly_count=len(X_anomaly_val)
        )
        
        # ìƒì„±í•œ ì´ìƒì¹˜ ì €ì¥
        synthetic_anomalies_by_type[anomaly_type] = synthetic_anomalies
        
        # í•©ì„± ì´ìƒì¹˜ë¡œ ê²€ì¦ ì„¸íŠ¸ ìƒì„±
        X_val_synthetic = np.vstack([X_normal_val, synthetic_anomalies])
        y_val_synthetic = np.concatenate([np.zeros(len(X_normal_val)), np.ones(len(synthetic_anomalies))])
        X_val_synthetic, y_val_synthetic = shuffle_data(X_val_synthetic, y_val_synthetic)
        
        synthetic_val_sets[anomaly_type] = (X_val_synthetic, y_val_synthetic)
        
        print(f"{anomaly_type} ê²€ì¦ ì„¸íŠ¸: {X_val_synthetic.shape}, ì •ìƒ: {np.sum(y_val_synthetic == 0)}, ì´ìƒ: {np.sum(y_val_synthetic == 1)}")
    
    # ê° ìœ í˜•ì—ì„œ 1/4ì”© ì´ìƒì¹˜ ìƒ˜í”Œë§í•˜ì—¬ í˜¼í•© ë°ì´í„°ì…‹ ìƒì„±
    print("\ní˜¼í•© ì´ìƒì¹˜(mixed) ê²€ì¦ ì„¸íŠ¸ ìƒì„± ì¤‘...")
    mixed_anomalies = []
    anomalies_per_type = len(X_anomaly_val) // len(ANOMALY_TYPES)  # ê° ìœ í˜•ë³„ë¡œ ê°€ì ¸ì˜¬ ì´ìƒì¹˜ ìˆ˜
    
    for anomaly_type in ANOMALY_TYPES:
        # ê° ìœ í˜•ì—ì„œ í•„ìš”í•œ ìˆ˜ë§Œí¼ ì´ìƒì¹˜ ì„ íƒ
        anomalies = synthetic_anomalies_by_type[anomaly_type]
        if len(anomalies) > anomalies_per_type:
            # ë¬´ì‘ìœ„ë¡œ í•„ìš”í•œ ìˆ˜ë§Œí¼ë§Œ ì„ íƒ
            indices = np.random.RandomState(RANDOM_SEED).choice(
                len(anomalies), anomalies_per_type, replace=False
            )
            selected_anomalies = anomalies[indices]
        else:
            # ì´ìƒì¹˜ ìˆ˜ê°€ ë¶€ì¡±í•˜ë©´ ì „ë¶€ ì‚¬ìš©
            selected_anomalies = anomalies
        
        mixed_anomalies.append(selected_anomalies)
    
    # ëª¨ë“  ì„ íƒëœ ì´ìƒì¹˜ í•©ì¹˜ê¸°
    mixed_anomalies = np.vstack(mixed_anomalies)
    
    # í˜¼í•© ì´ìƒì¹˜ë¡œ ê²€ì¦ ì„¸íŠ¸ ìƒì„±
    X_val_mixed = np.vstack([X_normal_val, mixed_anomalies])
    y_val_mixed = np.concatenate([np.zeros(len(X_normal_val)), np.ones(len(mixed_anomalies))])
    X_val_mixed, y_val_mixed = shuffle_data(X_val_mixed, y_val_mixed)
    
    # í˜¼í•© ì´ìƒì¹˜ ê²€ì¦ ì„¸íŠ¸ ì¶”ê°€
    synthetic_val_sets['mixed'] = (X_val_mixed, y_val_mixed)
    
    print(f"í˜¼í•©(mixed) ê²€ì¦ ì„¸íŠ¸: {X_val_mixed.shape}, ì •ìƒ: {np.sum(y_val_mixed == 0)}, ì´ìƒ: {np.sum(y_val_mixed == 1)}")
    print(f"í˜¼í•© ì´ìƒì¹˜ êµ¬ì„±: ê° ìœ í˜•ë‹¹ ì•½ {anomalies_per_type}ê°œì”©, ì´ {len(mixed_anomalies)}ê°œ")
    
    # ===== ìƒˆë¡œìš´ ë°©ì‹: GMM CoT ê¸°ë°˜ Synthetic Anomaly ìƒì„± =====
    # GMM CoT ê²€ì¦ ì„¸íŠ¸ ìƒì„±
    cot_validation_sets = generate_gmm_cot_validation_sets(
        X_normal_val=X_normal_val, 
        X_anomaly_val=X_anomaly_val,
        dataset_name=args.dataset_name,
        results_dir=results_dir
    )
    
    # ===== ëª¨ë“  ê²€ì¦ ì„¸íŠ¸ í†µí•© =====
    # ê¸°ì¡´ í•©ì„± ê²€ì¦ ì„¸íŠ¸ì™€ CoT ê²€ì¦ ì„¸íŠ¸ ê²°í•©
    all_synthetic_val_sets = {**synthetic_val_sets, **cot_validation_sets}
    
    print(f"\nğŸ“‹ ì „ì²´ ê²€ì¦ ì„¸íŠ¸ ìš”ì•½:")
    print(f"â€¢ ì‹¤ì œ ì´ìƒì¹˜ ê²€ì¦ ì„¸íŠ¸: 1ê°œ")
    print(f"â€¢ ê¸°ì¡´ í•©ì„± ì´ìƒì¹˜ ê²€ì¦ ì„¸íŠ¸: {len(synthetic_val_sets)}ê°œ ({list(synthetic_val_sets.keys())})")
    print(f"â€¢ GMM CoT í•©ì„± ì´ìƒì¹˜ ê²€ì¦ ì„¸íŠ¸: {len(cot_validation_sets)}ê°œ ({list(cot_validation_sets.keys())})")
    print(f"â€¢ ì´ ê²€ì¦ ì„¸íŠ¸ ìˆ˜: {len(all_synthetic_val_sets) + 1}ê°œ")
    
    # ===== t-SNE ì‹œê°í™” =====
    print(f"\n{'='*60}")
    print(f"ğŸ“ˆ t-SNE ì‹œê°í™” ìƒì„±")
    print(f"{'='*60}")
    
    # ì‹¤ì œ ì´ìƒì¹˜ì— ëŒ€í•œ ì‹œê°í™”
    visualize_tsne(
        X_test, y_test, None,
        title='Real Anomalies t-SNE Visualization',
        filename=os.path.join(results_dir, 'real_anomalies_tsne.png'),
        anomaly_types=None
    )
    
    # ëª¨ë“  í•©ì„± ì´ìƒì¹˜ ìœ í˜•ê³¼ ì •ìƒ ë°ì´í„° ê²°í•© (ê¸°ì¡´ ë°©ì‹)
    X_all_synthetic = X_normal_test.copy()
    y_all_synthetic = np.zeros(len(X_normal_test))
    y_types = np.zeros(len(X_normal_test))
    
    all_anomaly_types = []
    
    # ê¸°ì¡´ í•©ì„± ì´ìƒì¹˜ ìœ í˜• ì¶”ê°€ (mixed ì œì™¸)
    for i, anomaly_type in enumerate(ANOMALY_TYPES, 1):
        if anomaly_type in synthetic_val_sets:
            X_val, y_val = synthetic_val_sets[anomaly_type]
            synthetic_anomalies = X_val[y_val == 1]
            
            X_all_synthetic = np.vstack([X_all_synthetic, synthetic_anomalies])
            y_all_synthetic = np.concatenate([y_all_synthetic, np.ones(len(synthetic_anomalies))])
            y_types = np.concatenate([y_types, np.full(len(synthetic_anomalies), i)])
            all_anomaly_types.append(anomaly_type)
    
    # ê¸°ì¡´ + CoT í•©ì„± ì´ìƒì¹˜ í†µí•© ì‹œê°í™” (ìƒ˜í”Œë§í•˜ì—¬ í¬ê¸° ì œí•œ)
    if cot_validation_sets:
        X_all_with_cot = X_normal_test.copy()
        y_all_with_cot = np.zeros(len(X_normal_test))
        y_types_with_cot = np.zeros(len(X_normal_test))
        
        cot_anomaly_types = []
        
        # ê¸°ì¡´ í•©ì„± ì´ìƒì¹˜ ì¶”ê°€ (ìƒ˜í”Œë§)
        for i, anomaly_type in enumerate(ANOMALY_TYPES, 1):
            if anomaly_type in synthetic_val_sets:
                X_val, y_val = synthetic_val_sets[anomaly_type]
                synthetic_anomalies = X_val[y_val == 1]
                
                # ì‹œê°í™”ë¥¼ ìœ„í•´ ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´ ì‹œê°í™”ê°€ ì–´ë ¤ì›€)
                if len(synthetic_anomalies) > 200:
                    indices = np.random.choice(len(synthetic_anomalies), 200, replace=False)
                    synthetic_anomalies = synthetic_anomalies[indices]
                
                X_all_with_cot = np.vstack([X_all_with_cot, synthetic_anomalies])
                y_all_with_cot = np.concatenate([y_all_with_cot, np.ones(len(synthetic_anomalies))])
                y_types_with_cot = np.concatenate([y_types_with_cot, np.full(len(synthetic_anomalies), i)])
                cot_anomaly_types.append(f'Traditional-{anomaly_type}')
        
        # CoT í•©ì„± ì´ìƒì¹˜ ì¶”ê°€ (ìƒ˜í”Œë§)
        for i, (cot_type, (X_val, y_val)) in enumerate(cot_validation_sets.items(), len(ANOMALY_TYPES) + 1):
            synthetic_anomalies = X_val[y_val == 1]
            
            # ì‹œê°í™”ë¥¼ ìœ„í•´ ìƒ˜í”Œë§
            if len(synthetic_anomalies) > 200:
                indices = np.random.choice(len(synthetic_anomalies), 200, replace=False)
                synthetic_anomalies = synthetic_anomalies[indices]
            
            X_all_with_cot = np.vstack([X_all_with_cot, synthetic_anomalies])
            y_all_with_cot = np.concatenate([y_all_with_cot, np.ones(len(synthetic_anomalies))])
            y_types_with_cot = np.concatenate([y_types_with_cot, np.full(len(synthetic_anomalies), i)])
            cot_anomaly_types.append(f'CoT-{cot_type.replace("cot_", "")}')
        
        # í†µí•© ì‹œê°í™”
        visualize_tsne(
            X_all_with_cot, y_all_with_cot, y_types_with_cot,
            title='All Synthetic Anomalies t-SNE (Traditional + GMM CoT)',
            filename=os.path.join(results_dir, 'all_synthetic_anomalies_with_cot_tsne.png'),
            anomaly_types=cot_anomaly_types
        )
    
    # ê¸°ì¡´ í•©ì„± ì´ìƒì¹˜ ìœ í˜•ë³„ ì‹œê°í™”
    visualize_tsne(
        X_all_synthetic, y_all_synthetic, y_types,
        title='Traditional Synthetic Anomalies t-SNE Visualization',
        filename=os.path.join(results_dir, 'traditional_synthetic_anomalies_tsne.png'),
        anomaly_types=ANOMALY_TYPES
    )
    
    # í˜¼í•© ì´ìƒì¹˜ ì‹œê°í™” (ì•ˆì „í•˜ê²Œ)
    try:
        # y_types_mixed ìƒì„± (0: ì •ìƒ, 1: í˜¼í•© ì´ìƒì¹˜)
        y_types_mixed = np.zeros(len(y_val_mixed))
        y_types_mixed[y_val_mixed == 1] = 1
        
        # í˜¼í•© ì´ìƒì¹˜ ì‹œê°í™”
        visualize_tsne(
            X_val_mixed, y_val_mixed, y_types_mixed,
            title='Mixed Anomalies t-SNE Visualization',
            filename=os.path.join(results_dir, 'mixed_anomalies_tsne.png'),
            anomaly_types=['normal', 'mixed_anomalies']
        )
    except Exception as e:
        print(f"âš ï¸ í˜¼í•© ì´ìƒì¹˜ t-SNE ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ (ê±´ë„ˆëœ€): {e}")
    
    # ===== PyOD ëª¨ë¸ ì„ íƒ ì‹¤í—˜ ì‹¤í–‰ =====
    print(f"\n{'='*60}")
    print(f"ğŸ¤– PyOD ëª¨ë¸ ì„ íƒ ì‹¤í—˜ ì‹¤í–‰")
    print(f"{'='*60}")
    
    print(f"ì´ {len(all_synthetic_val_sets)}ê°œì˜ í•©ì„± ê²€ì¦ ì„¸íŠ¸ë¡œ ì‹¤í—˜:")
    for i, (val_name, (X_val, y_val)) in enumerate(all_synthetic_val_sets.items(), 1):
        val_type = "GMM CoT" if val_name.startswith("cot_") else "Traditional"
        print(f"  {i}. {val_name} ({val_type}) - í¬ê¸°: {X_val.shape}, ì´ìƒì¹˜: {np.sum(y_val == 1)}ê°œ")
    
    run_model_selection_experiment(
        X_normal_train=X_normal_train,
        X_val_real=X_val_real, y_val_real=y_val_real,
        synthetic_val_sets=all_synthetic_val_sets,  # ê¸°ì¡´ + CoT ëª¨ë“  ê²€ì¦ ì„¸íŠ¸
        X_test=X_test, y_test=y_test,
        results_dir=results_dir
    )
    
    print(f"\nğŸ‰ ì‹¤í—˜ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ëŠ” {results_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"\nğŸ“‹ ìƒì„±ëœ ì£¼ìš” íŒŒì¼ë“¤:")
    print(f"  â€¢ model_selection_results.csv - ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ê²°ê³¼")
    print(f"  â€¢ top3_models_results.csv - Top-3 ëª¨ë¸ ê²°ê³¼")
    print(f"  â€¢ top3_analysis_summary_report.txt - ë¶„ì„ ìš”ì•½ ë¦¬í¬íŠ¸")
    if cot_validation_sets:
        print(f"  â€¢ cot_anomalies_distribution.png - CoT ì´ìƒì¹˜ ë¶„í¬ (ì˜ë£Œ ë°ì´í„°ì¸ ê²½ìš°)")
    print(f"  â€¢ *_tsne.png - t-SNE ì‹œê°í™” íŒŒì¼ë“¤")
    print(f"  â€¢ top3_models_*_comparison.png - Top-3 ëª¨ë¸ ë¹„êµ ê·¸ë˜í”„ë“¤")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="GMM CoT ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€ ëª¨ë¸ ì„ íƒ ì‹¤í—˜")
    parser.add_argument("--dataset_name", type=str, required=True, 
                       help="ë°ì´í„°ì…‹ ì´ë¦„ (ì˜ˆ: cardiotocography, thyroid, arrhythmia ë“±)")
    args = parser.parse_args()
    
    try:
        main(args)
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì‹¤í—˜ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\n\nâŒ ì‹¤í—˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()