import numpy as np
import pandas as pd
from sklearn.mixture import GaussianMixture
from typing import List, Dict, Tuple, Any
import json
import random


class CoTAnoEvalGenerator:
    """
    CoT(Chain of Thought) ê¸°ë°˜ Dataset-specific AnoEval ìƒì„±ê¸°
    ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ í†µí•´ ë„ë©”ì¸ ì „ë¬¸ê°€ì˜ ì§€ì‹ì„ í™œìš©í•˜ì—¬
    í˜„ì‹¤ì ì´ê³  ë‹¤ì–‘í•œ ì´ìƒì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, seed=42):
        self.seed = seed
        np.random.seed(seed)
        random.seed(seed)
        
        # íƒœì•„ ì‹¬ë°•ìˆ˜ ë°ì´í„°ì…‹ì„ ìœ„í•œ ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ CoT í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.cot_prompt_templates = {
            "physiological_state": {
                "description": "Given this fetal heart rate dataset, what are abnormal physiological states?",
                "conditions": [
                    "Severe bradycardia with minimal variability",
                    "Tachycardia with high variability",
                    "Prolonged deceleration patterns",
                    "Absence of accelerations with high baseline"
                ]
            },
            "temporal_deterioration": {
                "description": "What combinations may indicate deterioration over time?",
                "conditions": [
                    "Progressively decreasing variability",
                    "Increasing baseline with decreasing accelerations",
                    "Prolonged periods of minimal variability",
                    "Late decelerations with reduced recovery"
                ]
            },
            "sensor_malfunction": {
                "description": "What conditions could result from sensor failure or noise?",
                "conditions": [
                    "Extremely high ASTV with zero MSTV",
                    "Impossible physiological combinations",
                    "Zero values in multiple critical parameters",
                    "Extreme outliers in histogram features"
                ]
            },
            "emergency_situations": {
                "description": "What patterns may appear in emergency situations like fetal distress?",
                "conditions": [
                    "Severe bradycardia with absent variability",
                    "Recurrent severe decelerations",
                    "Persistent minimal variability",
                    "Sinusoidal pattern indicators"
                ]
            },
            "statistical_anomalies": {
                "description": "What statistical combinations might seem unlikely or rare?",
                "conditions": [
                    "High baseline with low variability",
                    "Normal baseline with extreme histogram skewness",
                    "High accelerations with low movements",
                    "Contradictory trend and pattern indicators"
                ]
            }
        }
        
        # íŠ¹ì„± ì´ë¦„ê³¼ ì •ìƒ ë²”ìœ„ ì •ì˜ (ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜)
        self.feature_info = {
            'LB': {'name': 'Baseline', 'normal_range': (110, 160), 'unit': 'bpm'},
            'AC': {'name': 'Accelerations', 'normal_range': (0, 10), 'unit': 'count'},
            'FM': {'name': 'Fetal Movements', 'normal_range': (0, 500), 'unit': 'count'},
            'UC': {'name': 'Uterine Contractions', 'normal_range': (0, 10), 'unit': 'count'},
            'ASTV': {'name': 'Short Term Variability', 'normal_range': (20, 80), 'unit': 'ms'},
            'MSTV': {'name': 'Mean Short Term Variability', 'normal_range': (0.5, 7), 'unit': 'ms'},
            'ALTV': {'name': 'Long Term Variability', 'normal_range': (0, 50), 'unit': 'ms'},
            'MLTV': {'name': 'Mean Long Term Variability', 'normal_range': (0, 15), 'unit': 'ms'},
            'Variance': {'name': 'Variance', 'normal_range': (0, 100), 'unit': 'msÂ²'}
        }
    
    def generate_cot_conditions(self, X_normal: np.ndarray, feature_names: List[str]) -> List[Dict]:
        """
        CoT ê¸°ë°˜ìœ¼ë¡œ ì´ìƒì¹˜ ì¡°ê±´ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Parameters:
        - X_normal: ì •ìƒ ë°ì´í„°
        - feature_names: íŠ¹ì„± ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        
        Returns:
        - List of condition dictionaries
        """
        print("ğŸ§  CoT ê¸°ë°˜ ì´ìƒì¹˜ ì¡°ê±´ ìƒì„± ì¤‘...")
        
        all_conditions = []
        
        # ê° í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ëŒ€í•´ ì¡°ê±´ ìƒì„±
        for template_name, template_info in self.cot_prompt_templates.items():
            print(f"  ğŸ“‹ {template_name} í…œí”Œë¦¿ ì²˜ë¦¬ ì¤‘...")
            
            for condition_desc in template_info["conditions"]:
                # ê° ì¡°ê±´ì„ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ì¡°ê±´ìœ¼ë¡œ ë³€í™˜
                specific_conditions = self._convert_to_specific_conditions(
                    condition_desc, X_normal, feature_names
                )
                
                for specific_condition in specific_conditions:
                    condition_dict = {
                        'template': template_name,
                        'description': condition_desc,
                        'specific_condition': specific_condition,
                        'feature_constraints': specific_condition
                    }
                    all_conditions.append(condition_dict)
        
        print(f"âœ… ì´ {len(all_conditions)}ê°œì˜ CoT ì¡°ê±´ ìƒì„± ì™„ë£Œ")
        return all_conditions
    
    def _convert_to_specific_conditions(self, condition_desc: str, X_normal: np.ndarray, 
                                      feature_names: List[str]) -> List[Dict]:
        """
        í…ìŠ¤íŠ¸ ì¡°ê±´ì„ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ì¡°ê±´ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        """
        conditions = []
        
        # ì •ìƒ ë°ì´í„°ì˜ í†µê³„ ì •ë³´ ê³„ì‚°
        normal_stats = {}
        for i, feature in enumerate(feature_names):
            if i < X_normal.shape[1]:
                normal_stats[feature] = {
                    'mean': np.mean(X_normal[:, i]),
                    'std': np.std(X_normal[:, i]),
                    'min': np.min(X_normal[:, i]),
                    'max': np.max(X_normal[:, i]),
                    'q25': np.percentile(X_normal[:, i], 25),
                    'q75': np.percentile(X_normal[:, i], 75)
                }
        
        # ì¡°ê±´ë³„ êµ¬ì²´ì  ìˆ˜ì¹˜ ìƒì„±
        if "bradycardia" in condition_desc.lower():
            # ì„œë§¥: ë‚®ì€ ê¸°ì €ì„ 
            if 'LB' in normal_stats:
                conditions.append({
                    'LB': ('below', normal_stats['LB']['q25'] - normal_stats['LB']['std']),
                    'ASTV': ('below', normal_stats.get('ASTV', {}).get('q25', 30))
                })
        
        elif "tachycardia" in condition_desc.lower():
            # ë¹ˆë§¥: ë†’ì€ ê¸°ì €ì„ 
            if 'LB' in normal_stats:
                conditions.append({
                    'LB': ('above', normal_stats['LB']['q75'] + normal_stats['LB']['std']),
                    'ASTV': ('above', normal_stats.get('ASTV', {}).get('q75', 70))
                })
        
        elif "minimal variability" in condition_desc.lower():
            # ìµœì†Œ ë³€ë™ì„±
            conditions.append({
                'ASTV': ('below', 20),
                'MSTV': ('below', 1.0)
            })
        
        elif "extreme outliers" in condition_desc.lower():
            # ê·¹ë‹¨ì  ì´ìƒê°’
            for feature in ['ASTV', 'MSTV', 'Variance']:
                if feature in normal_stats:
                    conditions.append({
                        feature: ('above', normal_stats[feature]['max'] * 2)
                    })
        
        elif "zero values" in condition_desc.lower():
            # ì˜ê°’ ì¡°ê±´
            conditions.append({
                'ASTV': ('equal', 0),
                'AC': ('equal', 0),
                'FM': ('equal', 0)
            })
        
        elif "high baseline" in condition_desc.lower():
            # ë†’ì€ ê¸°ì €ì„  ì¡°ê±´
            if 'LB' in normal_stats:
                conditions.append({
                    'LB': ('above', 150),
                    'ASTV': ('below', normal_stats.get('ASTV', {}).get('mean', 50))
                })
        
        # ê¸°ë³¸ ì¡°ê±´ì´ ì—†ëŠ” ê²½ìš° ëœë¤ ì¡°ê±´ ìƒì„±
        if not conditions:
            conditions.append(self._generate_random_condition(normal_stats))
        
        return conditions
    
    def _generate_random_condition(self, normal_stats: Dict) -> Dict:
        """ëœë¤í•œ ì´ìƒì¹˜ ì¡°ê±´ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        condition = {}
        
        # ëœë¤í•˜ê²Œ 1-3ê°œì˜ íŠ¹ì„± ì„ íƒ
        selected_features = random.sample(list(normal_stats.keys()), 
                                        min(3, random.randint(1, len(normal_stats))))
        
        for feature in selected_features:
            stats = normal_stats[feature]
            
            # ëœë¤í•˜ê²Œ ì¡°ê±´ ìœ í˜• ì„ íƒ
            condition_type = random.choice(['above', 'below'])
            
            if condition_type == 'above':
                threshold = stats['q75'] + random.uniform(0.5, 2.0) * stats['std']
            else:
                threshold = stats['q25'] - random.uniform(0.5, 2.0) * stats['std']
                threshold = max(0, threshold)  # ìŒìˆ˜ ë°©ì§€
            
            condition[feature] = (condition_type, threshold)
        
        return condition
    
    def generate_soft_variants(self, base_condition: Dict, num_variants: int = 5) -> List[Dict]:
        """
        í•˜ë‚˜ì˜ ê¸°ë³¸ ì¡°ê±´ì—ì„œ soft variantë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Parameters:
        - base_condition: ê¸°ë³¸ ì¡°ê±´
        - num_variants: ìƒì„±í•  ë³€í˜• ìˆ˜
        
        Returns:
        - List of variant conditions
        """
        variants = []
        
        for _ in range(num_variants):
            variant = {}
            
            for feature, (operator, threshold) in base_condition.items():
                # ì„ê³„ê°’ì— ë…¸ì´ì¦ˆ ì¶”ê°€
                noise_factor = random.uniform(0.8, 1.2)
                new_threshold = threshold * noise_factor
                
                # ì¶”ê°€ì ì¸ ë³€ë™ì„± ì ìš©
                if random.random() < 0.3:  # 30% í™•ë¥ ë¡œ ì—°ì‚°ì ë³€ê²½
                    if operator == 'above':
                        new_operator = 'below' if random.random() < 0.5 else 'above'
                    elif operator == 'below':
                        new_operator = 'above' if random.random() < 0.5 else 'below'
                    else:
                        new_operator = operator
                else:
                    new_operator = operator
                
                variant[feature] = (new_operator, new_threshold)
            
            variants.append(variant)
        
        return variants
    
    def generate_combination_conditions(self, conditions: List[Dict], 
                                      num_combinations: int = 10) -> List[Dict]:
        """
        ë‘ ê°œ ì´ìƒì˜ ì¡°ê±´ì„ ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ ì¡°ê±´ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Parameters:
        - conditions: ê¸°ë³¸ ì¡°ê±´ë“¤
        - num_combinations: ìƒì„±í•  ì¡°í•© ìˆ˜
        
        Returns:
        - List of combined conditions
        """
        combinations = []
        
        for _ in range(num_combinations):
            # ëœë¤í•˜ê²Œ 2-3ê°œì˜ ì¡°ê±´ ì„ íƒ
            selected_conditions = random.sample(conditions, 
                                              min(len(conditions), random.randint(2, 3)))
            
            # ì¡°ê±´ë“¤ì„ ì¡°í•©
            combined_condition = {}
            
            for condition in selected_conditions:
                specific_cond = condition['specific_condition']
                
                for feature, constraint in specific_cond.items():
                    if feature not in combined_condition:
                        combined_condition[feature] = constraint
                    else:
                        # ê¸°ì¡´ ì¡°ê±´ê³¼ ì¶©ëŒí•˜ëŠ” ê²½ìš°, ë” ê·¹ë‹¨ì ì¸ ì¡°ê±´ ì„ íƒ
                        existing_op, existing_val = combined_condition[feature]
                        new_op, new_val = constraint
                        
                        if existing_op == new_op:
                            # ê°™ì€ ì—°ì‚°ìì¸ ê²½ìš° ë” ê·¹ë‹¨ì ì¸ ê°’ ì„ íƒ
                            if existing_op == 'above':
                                combined_condition[feature] = (existing_op, max(existing_val, new_val))
                            elif existing_op == 'below':
                                combined_condition[feature] = (existing_op, min(existing_val, new_val))
                        else:
                            # ë‹¤ë¥¸ ì—°ì‚°ìì¸ ê²½ìš° ëœë¤ ì„ íƒ
                            combined_condition[feature] = random.choice([
                                (existing_op, existing_val), 
                                (new_op, new_val)
                            ])
            
            combination_dict = {
                'template': 'combination',
                'description': f'Combination of {len(selected_conditions)} conditions',
                'specific_condition': combined_condition,
                'feature_constraints': combined_condition
            }
            
            combinations.append(combination_dict)
        
        return combinations
    
    def apply_semantic_perturbation(self, X_normal: np.ndarray, 
                                   num_samples: int = 100) -> np.ndarray:
        """
        ì˜ë¯¸ì  perturbationì„ ì ìš©í•˜ì—¬ ì´ìƒì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Parameters:
        - X_normal: ì •ìƒ ìƒ˜í”Œë“¤
        - num_samples: ìƒì„±í•  ì´ìƒì¹˜ ìˆ˜
        
        Returns:
        - ìƒì„±ëœ ì´ìƒì¹˜ë“¤
        """
        print("ğŸ”„ ì˜ë¯¸ì  perturbation ì ìš© ì¤‘...")
        
        # ì •ìƒ ìƒ˜í”Œë“¤ ì¤‘ ëœë¤ ì„ íƒ
        selected_indices = np.random.choice(len(X_normal), 
                                          min(num_samples, len(X_normal)), 
                                          replace=False)
        selected_samples = X_normal[selected_indices]
        
        perturbed_samples = []
        
        for sample in selected_samples:
            # ê° íŠ¹ì„±ì— ëŒ€í•´ ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ perturbation ì ìš©
            perturbed_sample = sample.copy()
            
            # ëœë¤í•˜ê²Œ 1-3ê°œì˜ íŠ¹ì„±ì„ ì„ íƒí•˜ì—¬ ë³€í˜•
            num_features_to_perturb = random.randint(1, min(3, len(sample)))
            features_to_perturb = random.sample(range(len(sample)), num_features_to_perturb)
            
            for feature_idx in features_to_perturb:
                original_value = sample[feature_idx]
                
                # íŠ¹ì„±ë³„ perturbation ì „ëµ
                perturbation_strategies = [
                    lambda x: x * random.uniform(1.5, 3.0),  # ì¦ê°€
                    lambda x: x * random.uniform(0.1, 0.5),  # ê°ì†Œ
                    lambda x: x + random.uniform(50, 100),   # ìƒìˆ˜ ì¶”ê°€
                    lambda x: max(0, x - random.uniform(20, 50)),  # ìƒìˆ˜ ê°ì†Œ
                    lambda x: 0 if random.random() < 0.3 else x,  # ê°€ë” 0ìœ¼ë¡œ ì„¤ì •
                ]
                
                strategy = random.choice(perturbation_strategies)
                perturbed_sample[feature_idx] = strategy(original_value)
            
            perturbed_samples.append(perturbed_sample)
        
        return np.array(perturbed_samples)
    
    def generate_cot_based_anomalies(self, X_normal: np.ndarray, feature_names: List[str],
                                    num_anomalies: int = 1000) -> Tuple[np.ndarray, List[Dict]]:
        """
        CoT ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì–‘í•œ ì´ìƒì¹˜ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Parameters:
        - X_normal: ì •ìƒ ë°ì´í„°
        - feature_names: íŠ¹ì„± ì´ë¦„ë“¤
        - num_anomalies: ìƒì„±í•  ì´ìƒì¹˜ ìˆ˜
        
        Returns:
        - ìƒì„±ëœ ì´ìƒì¹˜ë“¤ê³¼ ì‚¬ìš©ëœ ì¡°ê±´ë“¤
        """
        print("ğŸ¯ CoT ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„± ì‹œì‘...")
        
        # 1. CoT ì¡°ê±´ë“¤ ìƒì„±
        cot_conditions = self.generate_cot_conditions(X_normal, feature_names)
        
        # 2. Soft variants ìƒì„±
        print("ğŸ¨ Soft variants ìƒì„± ì¤‘...")
        all_conditions = cot_conditions.copy()
        
        for condition in cot_conditions[:10]:  # ì²˜ìŒ 10ê°œ ì¡°ê±´ì— ëŒ€í•´ì„œë§Œ
            variants = self.generate_soft_variants(condition['specific_condition'], 3)
            for variant in variants:
                variant_dict = {
                    'template': f"{condition['template']}_variant",
                    'description': f"Variant of {condition['description']}",
                    'specific_condition': variant,
                    'feature_constraints': variant
                }
                all_conditions.append(variant_dict)
        
        # 3. ì¡°í•© ì¡°ê±´ë“¤ ìƒì„±
        print("ğŸ§¬ ì¡°í•© ì¡°ê±´ë“¤ ìƒì„± ì¤‘...")
        combination_conditions = self.generate_combination_conditions(cot_conditions, 15)
        all_conditions.extend(combination_conditions)
        
        # 4. ì˜ë¯¸ì  perturbation ì ìš©
        print("âœï¸ ì˜ë¯¸ì  perturbation ì ìš© ì¤‘...")
        semantic_anomalies = self.apply_semantic_perturbation(X_normal, num_anomalies // 4)
        
        # 5. ì¡°ê±´ ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„±
        print("ğŸ”§ ì¡°ê±´ ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„± ì¤‘...")
        condition_based_anomalies = []
        
        remaining_anomalies = num_anomalies - len(semantic_anomalies)
        conditions_per_anomaly = max(1, len(all_conditions) // remaining_anomalies)
        
        for i in range(remaining_anomalies):
            condition_idx = i % len(all_conditions)
            condition = all_conditions[condition_idx]
            
            # ì¡°ê±´ì— ë§ëŠ” ì´ìƒì¹˜ ìƒì„±
            anomaly = self._generate_anomaly_from_condition(
                condition['specific_condition'], X_normal, feature_names
            )
            
            if anomaly is not None:
                condition_based_anomalies.append(anomaly)
        
        # 6. ëª¨ë“  ì´ìƒì¹˜ ê²°í•©
        all_anomalies = []
        
        if len(semantic_anomalies) > 0:
            all_anomalies.extend(semantic_anomalies)
        
        if len(condition_based_anomalies) > 0:
            all_anomalies.extend(condition_based_anomalies)
        
        # ë¶€ì¡±í•œ ê²½ìš° ì¶”ê°€ ìƒì„±
        while len(all_anomalies) < num_anomalies:
            # ëœë¤ ì¡°ê±´ìœ¼ë¡œ ì¶”ê°€ ì´ìƒì¹˜ ìƒì„±
            random_condition = random.choice(all_conditions)
            anomaly = self._generate_anomaly_from_condition(
                random_condition['specific_condition'], X_normal, feature_names
            )
            if anomaly is not None:
                all_anomalies.append(anomaly)
        
        # ìš”ì²­ëœ ìˆ˜ë§Œí¼ë§Œ ë°˜í™˜
        final_anomalies = np.array(all_anomalies[:num_anomalies])
        
        print(f"âœ… CoT ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„± ì™„ë£Œ: {len(final_anomalies)}ê°œ")
        print(f"ğŸ“Š ì‚¬ìš©ëœ ì¡°ê±´ ìˆ˜: {len(all_conditions)}ê°œ")
        
        return final_anomalies, all_conditions
    
    def _generate_anomaly_from_condition(self, condition: Dict, X_normal: np.ndarray,
                                       feature_names: List[str]) -> np.ndarray:
        """
        ì£¼ì–´ì§„ ì¡°ê±´ì— ë§ëŠ” ì´ìƒì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        """
        try:
            # ì •ìƒ ìƒ˜í”Œ ì¤‘ í•˜ë‚˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œì‘
            base_sample = X_normal[np.random.randint(0, len(X_normal))].copy()
            
            # ì¡°ê±´ì— ë”°ë¼ íŠ¹ì„±ê°’ ìˆ˜ì •
            for feature, (operator, threshold) in condition.items():
                if feature in feature_names:
                    feature_idx = feature_names.index(feature)
                    
                    if operator == 'above':
                        base_sample[feature_idx] = threshold + random.uniform(0, threshold * 0.1)
                    elif operator == 'below':
                        base_sample[feature_idx] = max(0, threshold - random.uniform(0, threshold * 0.1))
                    elif operator == 'equal':
                        base_sample[feature_idx] = threshold
            
            return base_sample
            
        except Exception as e:
            print(f"âš ï¸ ì¡°ê±´ ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return None


class EnhancedDataGenerator(SimpleDataGenerator):
    """
    CoT ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„±ì„ í¬í•¨í•œ í™•ì¥ëœ ë°ì´í„° ìƒì„±ê¸°
    """
    
    def __init__(self, seed=42):
        super().__init__(seed)
        self.cot_generator = CoTAnoEvalGenerator(seed)
    
    def generate_anomalies(self, X, y, anomaly_type, alpha=5, percentage=0.2, anomaly_count=None):
        """
        í™•ì¥ëœ ì´ìƒì¹˜ ìƒì„± í•¨ìˆ˜ (CoT ê¸°ë°˜ ì´ìƒì¹˜ í¬í•¨)
        """
        if anomaly_type == 'cot_based':
            # CoT ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„±
            X_normal = X[y == 0]
            
            # íŠ¹ì„± ì´ë¦„ ìƒì„± (ì‹¤ì œ ë°ì´í„°ì…‹ì— ë§ê²Œ ì¡°ì • í•„ìš”)
            feature_names = ['LB', 'AC', 'FM', 'UC', 'ASTV', 'MSTV', 'ALTV', 'MLTV', 
                           'DL', 'DS', 'DP', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 
                           'Mode', 'Mean', 'Median', 'Variance', 'Tendency']
            
            # ë°ì´í„° ì°¨ì›ì— ë§ê²Œ íŠ¹ì„± ì´ë¦„ ì¡°ì •
            feature_names = feature_names[:X.shape[1]]
            
            if anomaly_count is None:
                anomaly_count = np.sum(y == 1)
            
            cot_anomalies, conditions_used = self.cot_generator.generate_cot_based_anomalies(
                X_normal, feature_names, anomaly_count
            )
            
            print(f"ğŸ¯ CoT ê¸°ë°˜ ì´ìƒì¹˜ ìƒì„± ì™„ë£Œ: {len(cot_anomalies)}ê°œ")
            print(f"ğŸ“‹ ì‚¬ìš©ëœ ì¡°ê±´ ìœ í˜•: {len(set([c['template'] for c in conditions_used]))}ê°œ")
            
            return cot_anomalies
        
        else:
            # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì´ìƒì¹˜ ìƒì„±
            return super().generate_anomalies(X, y, anomaly_type, alpha, percentage, anomaly_count)